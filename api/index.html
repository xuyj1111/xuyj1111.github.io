{"themeConfig":{"themeName":"notes","postPageSize":10,"archivesPageSize":50,"siteName":"洗衣机的博客","siteDescription":"【一名Java开发】slave👉https://www.cnblogs.com/xuyj1111/","footerInfo":"","showFeatureImage":true,"domain":"https://xuyj1111.github.io","postUrlFormat":"SHORT_ID","tagUrlFormat":"SHORT_ID","dateFormat":"YYYY-MM-DD","feedFullText":false,"feedCount":10,"archivesPath":"archives","postPath":"","tagPath":""},"posts":[{"content":" 一个 Job 由多个 Step 组成 Step 有两种实现方式：Tasklet和Read-Process-Write 两种实现方式可以单独使用，也可以一起使用 Spring Batch 提供了 skip 和 retry 机制 使用 Tasklet Tasklet 只会执行一次，实现org.springframework.batch.core.step.tasklet.Tasklet接口，在execute方法中编写逻辑 当 Tasklet 实现类返回RepeatStatus.FINISHED，Job 会执行下一个 Step @Configuration @EnableBatchProcessing public class MyJobConfiguration { @Autowired private JobBuilderFactory jobBuilderFactory; @Autowired private StepBuilderFactory stepBuilderFactory; @Bean public Step step1() { return stepBuilderFactory.get(&quot;step1&quot;) .tasklet((stepContribution, chunkContext) -&gt; { // Step1的逻辑 return RepeatStatus.FINISHED; }).build(); } @Bean public Step step2() { return stepBuilderFactory.get(&quot;step2&quot;) .tasklet((stepContribution, chunkContext) -&gt; { // Step2的逻辑 return RepeatStatus.FINISHED; }).build(); } @Bean public Step step3() { return stepBuilderFactory.get(&quot;step3&quot;) .tasklet((stepContribution, chunkContext) -&gt; { // Step3的逻辑 return RepeatStatus.FINISHED; }).build(); } @Bean public Job myJob() { return jobBuilderFactory.get(&quot;myJob&quot;) .start(step1()) .next(step2()) .next(step3()) .build(); } } 使用 Read-Process-Write Read-Process-Write 会执行多次，chunk(int chunkSize)中的值表示一次 Read-Process-Write 的处理量 此次使用FlatFileItemReader读数据，JpaItemWriter写数据 public class MessageProcessor implements ItemProcessor&lt;Message, Message&gt; { @Override public Message process(Message item) { System.out.println(&quot;item: &quot; + item.toString()); return item; } } public class MessageItemReadListener implements ItemReadListener&lt;Message&gt; { // } public class MessageWriteListener implements ItemWriteListener&lt;Message&gt; { // } public class MessageLineMapper implements LineMapper&lt;Message&gt; { // } public class Message { // } public class MessageMigrationJobConfiguration { private static final Integer CHUNK_SIZE = 4; private static final String MESSAGE_FILE = &quot;src/main/resources/file/message.txt&quot;; private static final Integer SKIP_LIMIT = 1; @Autowired private JobBuilderFactory jobBuilderFactory; @Autowired private StepBuilderFactory stepBuilderFactory; @Autowired private EntityManagerFactory entityManager; /** * @Description: 构建job */ @Bean public Job messageMigrationJob(@Qualifier(&quot;messageMigrationStep&quot;) Step messageMigrationStep) { return jobBuilderFactory.get(&quot;messageMigrationJob&quot;) .flow(messageMigrationStep) .end() .build(); } /** * @Description: 构建step */ @Bean public Step messageMigrationStep(@Qualifier(&quot;jsonMessageReader&quot;) FlatFileItemReader&lt;Message&gt; jsonMessageReader, @Qualifier(&quot;messageProcessor&quot;) MessageProcessor messageProcessor, @Qualifier(&quot;messageItemWriter&quot;) JpaItemWriter&lt;Message&gt; messageItemWriter) { return stepBuilderFactory.get(&quot;messageMigrationStep&quot;) .&lt;Message, Message&gt;chunk(CHUNK_SIZE) .reader(jsonMessageReader).faultTolerant().skip(JsonParseException.class).skipLimit(SKIP_LIMIT) .listener(new MessageItemReadListener()) .processor(messageProcessor) .writer(messageItemWriter).faultTolerant().skip(Exception.class).skipLimit(SKIP_LIMIT) .listener(new MessageWriteListener()) .build(); } /** * @Description: 构建reader * FlatFileItemReader：从文件里面一行一行的读取数据 * .setResource：设置文件路径 * .setLineMapper：把一行文本映射为Message类，自定义类 */ @Bean public FlatFileItemReader&lt;Message&gt; jsonMessageReader() { FlatFileItemReader&lt;Message&gt; reader = new FlatFileItemReader&lt;&gt;(); reader.setResource(new FileSystemResource(new File(MESSAGE_FILE))); reader.setLineMapper(new MessageLineMapper()); return reader; } @Bean public MessageProcessor messageProcessor() { return new MessageProcessor(); } /** * @Description: 构建writer */ @Bean public JpaItemWriter&lt;Message&gt; messageItemWriter() { JpaItemWriter&lt;Message&gt; writer = new JpaItemWriter&lt;&gt;(); writer.setEntityManagerFactory(entityManager); return writer; } } 注解 @EnableBatchProcessing打开Batch。如果多 job 的情况，需要把 EnableBatchProcessing 注解的 modular 设置为 true ，让每个 Job 使用自己的 ApplicationConext @JobScope作用域注解。应用于 step 或 reader、processor、writer 等组件的 @Bean 方法中，用于指定组件的生命周期范围为 Job。使用 @JobScope 注解的组件，将在 Job 执行期间实例化一次，然后在 Job 执行完成后销毁。这使得组件可以拥有 Job 的上下文，包括 JobParameters、ExecutionContext 等，从而可以在 Job 执行期间获取 Job 的相关信息。 常用类 JobLauncher启动 job 类 JobRegistry存储多个 job 实例，JobRegistry 可以通过 job 实例的唯一名称获取 job JobBuilderFactory构建 JobBuilder 对象的工厂类 通常用JobBuilder get(String name)构建 JobBuilder StepBuilderFactory构建 StepBuilder 对象的工厂类 通常用StepBuilder get(String name)构建 StepBuilder JobParameters 存储一组有序的键值对，这些键值用于 Job 或 Step 的运行时参数 @Autowired private JobLauncher jobLauncher; public void executeJob(Job job) { JobParameters params = new JobParametersBuilder() .addLong(key, value, true) .addString(key, value, true) .toJobParameters(); jobLauncher.run(job, params) } 在构建 job 时（或step/tasklet/chunk/reader...）需要参数信息，使用@Value(&quot;#{jobParameters['...']}&quot;)注解的方式注入 需要使用 @JobScope 注解 @Bean @JobScope ItemProcessor&lt;Xxx, Xxx&gt; processor(@Value(&quot;#{jobParameters['Xxx']}&quot;) String Xxx, @Value(&quot;#{jobParameters['Xxx']}&quot;) String Xxx) { return null; } JobBuilder 用来创建 Job 实例 常用方法👇 name(String name)为Job实例指定名称 incrementer(JobParametersIncrementer incrementer)指定 JobParametersIncrementer 实例，用于生成 Job 参数 start(Step step)返回 SimpleJobBuilder，指定 Job 实例的第一个 Step 实例 flow(Step step)返回 JobFlowBuilder，指定 Job 实例的第一个 Step 实例 listener(JobExecutionListener listener)指定 JobExecutionListener 实例，用于监听 Job 的执行 listener(StepExecutionListener listener)指定 StepExecutionListener 实例，用于监听 Job 的每个 Step 的执行 validator(JobParametersValidator validator)指定 JobParametersValidator 实例，用于验证 Job 参数的合法性 build()构建 Job 实例 Job Job 有以下几种： SimpleJob包含一个 Step，执行完 Step 后即结束 FlowJob包含多个 Step 组成的逻辑流，根据 Step 执行结果状态，通过决策器实现分支 SplitJob包含多个 Step，这些 Step 可以并行执行 ChildJob在一个 Job 中可以包含其他 Job，形成树形结构，父Job 可以决定 子Job 的执行顺序和执行条件 CompositeJob通过讲多个 Job 组合在一起，实现一个 Job 包含多个 子Job 的效果，子Job 可以并行或串行执行，相互独立 p.s. 这些 Job 之间并不是互斥的，可以混合使用。可以使用JobStepBuilder将一个 Job 封装成 Step，然后在另一个 Job 中引用这个 Step StepBuilder 用来创建 Step 实例 常用方法👇 tasklet(Tasklet tasklet)指定 Step 中使用的 Tasklet，每个 Step 至少要有一个 Tasklet chunk(int chunkSize)指定每次读取多少数据进行处理，以及处理完后一次性写出的数据量 reader(ItemReader&lt;? extends T&gt; itemReader)指定 Step 中使用的 ItemReader processor(ItemProcessor&lt;? super T, ? extends S&gt; itemProcessor)指定 Step 中使用的 ItemProcessor writer(ItemWriter&lt;? super S&gt; itemWriter)指定 Step 中使用的 ItemWriter allowStartIfComplete(boolean allowStart)是否允许 Step 在上一次执行完成后立即再次执行 flow(Flow flow)返回 FlowStepBuilder，指定 Step 的 Flow 实例 Step Step 有以下几种： SimpleStep指定读、处理、写操作【单线程】 ChunkOrientedTasklet可以包揽读、处理、写操作【单线程】 TaskletStep指定并执行一个 Tasklet【单线程】 FlowStep中有一个 Flow 实例，Flow 实例中可以有多个 Step，可进行条件控制，如跳过某些步骤、重试某些步骤等【单线程】 多线程的 Step 有SimpleAsyncTaskExecutorStep、TaskExecutorStep、PartitionStep Listener Listener 接口需要实现使用，都有beforeXxx和afterXxx方法。在对应位置使用，如 Step 的监听器，在创建 Step 时使用；Job 的监听器，在创建 Job 时使用 常用接口👇 StepExecutionListenerstep 执行监听器 ItemReadListenerstep 读监听器 ItemWriteListenerstep 写监听器 JobExecutionListenerjob 执行监听器 ItemReader step 的读操作，SpringBatch 提供多个实现类👇 JdbcCursorItemReader用于从 JDBC 游标检索结果集 JdbcPagingItemReader用于从 JDBC 分页检索结果集 HibernateCursorItemReader用于从 Hibernate 游标检索结果集 HibernatePagingItemReader用于从 Hibernate 分页检索结果集 JpaPagingItemReader用于从 JPA 分页检索结果集 FlatFileItemReader用于从文件中读取数据 StaxEventItemReader读取 XML 文件 JsonItemReader读取 Json 格式数据 自定义 ItemReader：实现 ItemReader 接口，并重写 read 方法，该方法需要返回一个对象，如果没有读到数据则返回 null ItemWriter step 的写操作，SpringBatch 提供多个实现类👇 JdbcBatchItemWriter将数据批量写入关系型数据库 JpaItemWriter将数据批量写入 JPA 实体类 HibernateItemWriter将数据批量写入 Hibernate 实体类 FlatFileItemWriter将数据写入文本文件 MultiResourceItemWriter将数据写入多个文件 MongoItemWriter将数据批量写入 MongoDB HdfsTextItemWriter将数据写入 HDFS 文件 自定义 ItemWriter：通过实现 ItemWriter 接口，并重写 write 方法 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"}],"title":"【Java】SpringBatch 纯纯的笔记","feature":"","link":"https://xuyj1111.github.io/s4LoWAgBB/","stats":{"text":"8 min read","time":462000,"words":1731,"minutes":8},"date":"2023-03-02 10:00:33","dateFormat":"2023-03-02"},{"content":"三种 ThreadLocal 分别是： jdk 提供的ThreadLocal jdk 提供的InheritableThreadLocal 阿里巴巴提供的TransmittableThreadLocal 文章中 demo 的环境代码👇 private ThreadLocal&lt;Object&gt; t = new ThreadLocal&lt;&gt;(); private ThreadLocal&lt;Object&gt; it = new InheritableThreadLocal&lt;&gt;(); private ThreadLocal tt = new TransmittableThreadLocal(); private void printForThreadLocal() { System.out.println(Thread.currentThread().getName() + &quot;:&quot; + t.get()); } private void printForInheritableThreadLocal() { System.out.println(Thread.currentThread().getName() + &quot;:&quot; + it.get()); } private void printForTransmittableThreadLocal() { System.out.println(Thread.currentThread().getName() + &quot;:&quot; + tt.get()); } /** * @Description: 创建线程池 */ private Executor createThreadPool() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(1); executor.setMaxPoolSize(10); executor.setKeepAliveSeconds(60); executor.setQueueCapacity(60); executor.setThreadNamePrefix(&quot;myThreadPool: &quot;); executor.setTaskDecorator(new MyTaskDecorator()); executor.initialize(); return executor; } ThreadLocal 线程变量，仅供当前线程使用，不存在多线程分享变量问题 缺点：父子线程不可传递 三个方法： void set(Object value)填充变量 T get()获取变量 void remove()删除变量【当线程结束后，线程变量也会被回收，显示的调用remove并不是必须的操作，但可以加快内存回收的速度】 最简单的 ThreadLocal 用法👇 证明线程之间不共享 ThreadLocal 中的值 @Test public void test01ThreadLocal() { t.set(1); new Thread(() -&gt; printForThreadLocal()).start(); printForThreadLocal(); } InheritableThreadLocal 是 ThreadLocal 的子类，实现了父子线程共享变量问题 缺点：在使用线程池时，父子线程共享变量仍有问题 实现父子线程共享变量👇 @Test public void test01InheritableThreadLocal() { it.set(1); new Thread(() -&gt; printForInheritableThreadLocal()).start(); printForInheritableThreadLocal(); } 基本数据类型不可证明父子线程指向同一对象👇 @SneakyThrows @Test public void test02InheritableThreadLocal() { it.set(1); printForInheritableThreadLocal(); new Thread(() -&gt; { printForInheritableThreadLocal(); it.set(2); printForInheritableThreadLocal(); }).start(); Thread.sleep(500); printForInheritableThreadLocal(); } InheritableThreadLocal中子父线程中指向同一对象👇 @SneakyThrows @Test public void test03InheritableThreadLocal() { TestDTO testDTO = new TestDTO(); testDTO.setName(&quot;张三&quot;); testDTO.setAge(20); it.set(testDTO); printForInheritableThreadLocal(); new Thread(() -&gt; { printForInheritableThreadLocal(); TestDTO pp = (TestDTO) it.get(); pp.setName(&quot;李四&quot;); it.set(pp); printForInheritableThreadLocal(); }).start(); Thread.sleep(500); printForInheritableThreadLocal(); } 线程池在init新的线程时，会将主线程的InheritableThreadLocal传递给子线程👇 @SneakyThrows @Test public void test04InheritableThreadLocal() { it.set(1); printForInheritableThreadLocal(); Executor threadPool = createThreadPool(); threadPool.execute(() -&gt; printForInheritableThreadLocal()); printForInheritableThreadLocal(); } 但如果在init子线程时，主线程InheritableThreadLocal中值为null，子线程也是null； 之后主线程被赋了新值，已经被init的子线程再次被调用时，主线程不会赋值给子线程（当前线程池大小为1，则可实现二次调用创建的子线程）👇 @SneakyThrows @Test public void test05InheritableThreadLocal() { Executor threadPool = createThreadPool(); threadPool.execute(() -&gt; printForInheritableThreadLocal()); it.set(1); threadPool.execute(() -&gt; printForInheritableThreadLocal()); printForInheritableThreadLocal(); } TransmittableThreadLocal 解决了InheritableThreadLocal在线程池时父子线程传递的问题👇 @Test public void test01TransmittableThreadLocal() { Executor threadPool = TtlExecutors.getTtlExecutor(createThreadPool()); threadPool.execute(() -&gt; printForTransmittableThreadLocal()); tt.set(1); threadPool.execute(() -&gt; printForTransmittableThreadLocal()); printForTransmittableThreadLocal(); } ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"}],"title":"【Java】三种 ThreadLocal 的简单使用","feature":"","link":"https://xuyj1111.github.io/Kbdumv2S0/","stats":{"text":"3 min read","time":170000,"words":612,"minutes":3},"date":"2023-02-19 23:33:11","dateFormat":"2023-02-19"},{"content":" 玩转Spring中强大的spel表达式！，by 无情的BUG杀手 Spel 概述 Spring 表达式语言全称为 “Spring Expression Language”，缩写为 “SpEL”，类似于 Struts2x 中使用的 OGNL 表达式语言，能在运行时构建复杂表达式、存取对象图属性、对象方法调用等等，并且能与 Spring 功能完美整合，如能用来配置 Bean 定义。 表达式语言给静态 Java 语言增加了动态功能。 SpEL 是单独模块，只依赖于 core 模块，不依赖于其他模块，可以单独使用。 Spel 能干什么? 表达式语言一般是用最简单的形式完成最主要的工作，减少我们的工作量。 SpEL 支持如下表达式： 一、基本表达式： 字面量表达式、关系，逻辑与算数运算表达式、字符串连接及截取表达式、三目运算及 Elivis 表达式、正则表达式、括号优先级表达式； 二、类相关表达式： 类类型表达式、类实例化、instanceof 表达式、变量定义及引用、赋值表达式、自定义函数、对象属性存取及安全导航表达式、对象方法调用、Bean 引用； 三、集合相关表达式： 内联 List、内联数组、集合，字典访问、列表，字典，数组修改、集合投影、集合选择；不支持多维内联数组初始化；不支持内联字典定义； 四、其他表达式：模板表达式。 注：SpEL 表达式中的关键字是不区分大小写的。 SpEL 基础 HelloWorld 首先准备支持 SpEL 的 Jar 包：“org.springframework.expression-3.0.5.RELEASE.jar” 将其添加到类路径中。 SpEL 在求表达式值时一般分为四步，其中第三步可选：首先构造一个解析器，其次解析器解析字符串表达式，在此构造上下文，最后根据上下文得到表达式运算后的值。 让我们看下代码片段吧： package com.javacode2018.spel; import org.junit.Test; import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.ExpressionParser; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; public class SpelTest { @Test public void test1() { ExpressionParser parser = new SpelExpressionParser(); Expression expression = parser.parseExpression(&quot;('Hello' + ' World').concat(#end)&quot;); EvaluationContext context = new StandardEvaluationContext(); context.setVariable(&quot;end&quot;, &quot;!&quot;); System.out.println(expression.getValue(context)); } } 输出 Hello World! 接下来让我们分析下代码： 1）创建解析器：SpEL 使用 ExpressionParser 接口表示解析器，提供 SpelExpressionParser 默认实现； 2）解析表达式：使用 ExpressionParser 的 parseExpression 来解析相应的表达式为 Expression 对象。 3）构造上下文：准备比如变量定义等等表达式需要的上下文数据。 4）求值：通过 Expression 接口的 getValue 方法根据上下文获得表达式值。 是不是很简单，接下来让我们看下其具体实现及原理吧。 SpEL 原理及接口 SpEL 提供简单的接口从而简化用户使用，在介绍原理前让我们学习下几个概念： 一、表达式： 表达式是表达式语言的核心，所以表达式语言都是围绕表达式进行的，从我们角度来看是 “干什么”； 二、解析器： 用于将字符串表达式解析为表达式对象，从我们角度来看是 “谁来干”； 三、上下文： 表达式对象执行的环境，该环境可能定义变量、定义自定义函数、提供类型转换等等，从我们角度看是 “在哪干”； 四、根对象及活动上下文对象： 根对象是默认的活动上下文对象，活动上下文对象表示了当前表达式操作的对象，从我们角度看是 “对谁干”。 理解了这些概念后，让我们看下 SpEL 如何工作的呢，如图所示： 工作原理 1.首先定义表达式：“1+2”； 2.定义解析器ExpressionParser实现，SpEL提供默认实现SpelExpressionParser； 2.1.SpelExpressionParser解析器内部使用Tokenizer类进行词法分析，即把字符串流分析为记号流，记号在SpEL使用Token类来表示； 2.2.有了记号流后，解析器便可根据记号流生成内部抽象语法树；在SpEL中语法树节点由SpelNode接口实现代表：如OpPlus表示加操作节点、IntLiteral表示int型字面量节点；使用SpelNodel实现组成了抽象语法树； 2.3.对外提供Expression接口来简化表示抽象语法树，从而隐藏内部实现细节，并提供getValue简单方法用于获取表达式值；SpEL提供默认实现为SpelExpression； 3.定义表达式上下文对象（可选），SpEL使用EvaluationContext接口表示上下文对象，用于设置根对象、自定义变量、自定义函数、类型转换器等，SpEL提供默认实现StandardEvaluationContext； 4.使用表达式对象根据上下文对象（可选）求值（调用表达式对象的getValue方法）获得结果。 接下来让我们看下 SpEL 的主要接口吧： ExpressionParser 接口 表示解析器，默认实现是 org.springframework.expression.spel.standard 包中的 SpelExpressionParser 类，使用 parseExpression 方法将字符串表达式转换为 Expression 对象，对于 ParserContext 接口用于定义字符串表达式是不是模板，及模板开始与结束字符： public interface ExpressionParser { Expression parseExpression(String expressionString) throws ParseException; Expression parseExpression(String expressionString, ParserContext context) throws ParseException; } 来看下示例： @Test public void testParserContext() { ExpressionParser parser = new SpelExpressionParser(); ParserContext parserContext = new ParserContext() { @Override public boolean isTemplate() { return true; } @Override public String getExpressionPrefix() { return &quot;#{&quot;; } @Override public String getExpressionSuffix() { return &quot;}&quot;; } }; String template = &quot;#{'Hello '}#{'World!'}&quot;; Expression expression = parser.parseExpression(template, parserContext); System.out.println(expression.getValue()); } 在此我们演示的是使用 ParserContext 的情况，此处定义了 ParserContext 实现：定义表达式是模块，表达式前缀为 “#{”，后缀为“}”；使用 parseExpression 解析时传入的模板必须以“#{” 开头，以 “}” 结尾，如 &quot;#{'Hello '}#{'World!'}&quot;。 默认传入的字符串表达式不是模板形式，如之前演示的 Hello World。 EvaluationContext 接口 表示上下文环境，默认实现是 org.springframework.expression.spel.support 包中的 StandardEvaluationContext 类，使用 setRootObject 方法来设置根对象，使用 setVariable 方法来注册自定义变量，使用 registerFunction 来注册自定义函数等等。 Expression 接口 表示表达式对象，默认实现是 org.springframework.expression.spel.standard 包中的 SpelExpression，提供 getValue 方法用于获取表达式值，提供 setValue 方法用于设置对象值。 了解了 SpEL 原理及接口，接下来的事情就是 SpEL 语法了。 SpEL 语法 基本表达式 字面量表达式 SpEL 支持的字面量包括：字符串、数字类型（int、long、float、double）、布尔类型、null 类型。 类型示例字符串 String str1 = parser.parseExpression(&quot;'Hello World!'&quot;).getValue(String.class); 数字类型 int int1 = parser.parseExpression(&quot;1&quot;).getValue(Integer.class); long long1 = parser.parseExpression(&quot;-1L&quot;).getValue(long.class); float float1 = parser.parseExpression(&quot;1.1&quot;).getValue(Float.class); double double1 = parser.parseExpression(&quot;1.1E+2&quot;).getValue(double.class); int hex1 = parser.parseExpression(&quot;0xa&quot;).getValue(Integer.class); long hex2 = parser.parseExpression(&quot;0xaL&quot;).getValue(long.class); 布尔类型 boolean true1 = parser.parseExpression(&quot;true&quot;).getValue(boolean.class); boolean false1 = parser.parseExpression(&quot;false&quot;).getValue(boolean.class);null 类型 Object null1 = parser.parseExpression(&quot;null&quot;).getValue(Object.class); @Test public void test2() { ExpressionParser parser = new SpelExpressionParser(); String str1 = parser.parseExpression(&quot;'Hello World!'&quot;).getValue(String.class); int int1 = parser.parseExpression(&quot;1&quot;).getValue(Integer.class); long long1 = parser.parseExpression(&quot;-1L&quot;).getValue(long.class); float float1 = parser.parseExpression(&quot;1.1&quot;).getValue(Float.class); double double1 = parser.parseExpression(&quot;1.1E+2&quot;).getValue(double.class); int hex1 = parser.parseExpression(&quot;0xa&quot;).getValue(Integer.class); long hex2 = parser.parseExpression(&quot;0xaL&quot;).getValue(long.class); boolean true1 = parser.parseExpression(&quot;true&quot;).getValue(boolean.class); boolean false1 = parser.parseExpression(&quot;false&quot;).getValue(boolean.class); Object null1 = parser.parseExpression(&quot;null&quot;).getValue(Object.class); System.out.println(&quot;str1=&quot; + str1); System.out.println(&quot;int1=&quot; + int1); System.out.println(&quot;long1=&quot; + long1); System.out.println(&quot;float1=&quot; + float1); System.out.println(&quot;double1=&quot; + double1); System.out.println(&quot;hex1=&quot; + hex1); System.out.println(&quot;hex2=&quot; + hex2); System.out.println(&quot;true1=&quot; + true1); System.out.println(&quot;false1=&quot; + false1); System.out.println(&quot;null1=&quot; + null1); } 输出 str1=Hello World! int1=1 long1=-1 float1=1.1 double1=110.0 hex1=10 hex2=10 true1=true false1=false null1=null 算数运算表达式 SpEL 支持加 (+)、减 (-)、乘 (*)、除 (/)、求余（%）、幂（^）运算。 类型示例加减乘除 int result1 = parser.parseExpression(&quot;1+2-3*4/2&quot;).getValue(Integer.class);//-3 求余 int result2 = parser.parseExpression(&quot;4%3&quot;).getValue(Integer.class);//1 幂运算 int result3 = parser.parseExpression(&quot;2^3&quot;).getValue(Integer.class);//8 SpEL 还提供求余（MOD）和除（DIV）而外两个运算符，与 “%” 和“/”等价，不区分大小写。 关系表达式 等于（==）、不等于 (!=)、大于 (&gt;)、大于等于 (&gt;=)、小于 (&lt;)、小于等于 (&lt;=)，区间（between）运算。 如parser.parseExpression(&quot;1&gt;2&quot;).getValue(boolean.class);将返回 false； 而parser.parseExpression(&quot;1 between {1, 2}&quot;).getValue(boolean.class);将返回 true。 between运算符右边操作数必须是列表类型，且只能包含2个元素。第一个元素为开始，第二个元素为结束，区间运算是包含边界值的，即 xxx&gt;=list.get(0) &amp;&amp; xxx&lt;=list.get(1)。 SpEL 同样提供了等价的 “EQ” 、“NE”、 “GT”、“GE”、 “LT” 、“LE” 来表示等于、不等于、大于、大于等于、小于、小于等于，不区分大小写。 @Test public void test3() { ExpressionParser parser = new SpelExpressionParser(); boolean v1 = parser.parseExpression(&quot;1&gt;2&quot;).getValue(boolean.class); boolean between1 = parser.parseExpression(&quot;1 between {1,2}&quot;).getValue(boolean.class); System.out.println(&quot;v1=&quot; + v1); System.out.println(&quot;between1=&quot; + between1); } 输出 v1=false between1=true 逻辑表达式 且（and 或者 &amp;&amp;）、或 (or 或者 ||)、非 (! 或 NOT)。 @Test public void test4() { ExpressionParser parser = new SpelExpressionParser(); boolean result1 = parser.parseExpression(&quot;2&gt;1 and (!true or !false)&quot;).getValue(boolean.class); boolean result2 = parser.parseExpression(&quot;2&gt;1 &amp;&amp; (!true || !false)&quot;).getValue(boolean.class); boolean result3 = parser.parseExpression(&quot;2&gt;1 and (NOT true or NOT false)&quot;).getValue(boolean.class); boolean result4 = parser.parseExpression(&quot;2&gt;1 &amp;&amp; (NOT true || NOT false)&quot;).getValue(boolean.class); System.out.println(&quot;result1=&quot; + result1); System.out.println(&quot;result2=&quot; + result2); System.out.println(&quot;result3=&quot; + result3); System.out.println(&quot;result4=&quot; + result4); } 输出 result1=true result2=true result3=true result4=false 字符串连接及截取表达式 使用 “+” 进行字符串连接，使用 “'String'[0] [index]” 来截取一个字符，目前只支持截取一个，如 “'Hello' + 'World!'” 得到 “Hello World!”；而“'Hello World!'[0]” 将返回“H”。 三目运算 三目运算符 “表达式 1? 表达式 2: 表达式 3” 用于构造三目运算表达式，如 “2&gt;1?true:false” 将返回 true； Elivis 运算符 Elivis 运算符 “表达式 1?: 表达式 2” 从 Groovy 语言引入用于简化三目运算符的，当表达式 1 为非 null 时则返回表达式 1，当表达式 1 为 null 时则返回表达式 2，简化了三目运算符方式 “表达式 1? 表达式 1: 表达式 2”，如“null?:false” 将返回 false，而 “true?:false” 将返回 true； 正则表达式 使用 “str matches regex，如“'123' matches '\\d{3}'” 将返回 true； 括号优先级表达式 使用 “(表达式)” 构造，括号里的具有高优先级。 类相关表达式 类类型表达式 使用 “T(Type)” 来表示 java.lang.Class 实例，“Type”必须是类全限定名，“java.lang”包除外，即该包下的类可以不指定包名；使用类类型表达式还可以进行访问类静态方法及类静态字段。 具体使用方法如下： @Test public void testClassTypeExpression() { ExpressionParser parser = new SpelExpressionParser(); //java.lang包类访问 Class&lt;String&gt; result1 = parser.parseExpression(&quot;T(String)&quot;).getValue(Class.class); System.out.println(result1); //其他包类访问 String expression2 = &quot;T(com.javacode2018.spel.SpelTest)&quot;; Class&lt;SpelTest&gt; value = parser.parseExpression(expression2).getValue(Class.class); System.out.println(value == SpelTest.class); //类静态字段访问 int result3 = parser.parseExpression(&quot;T(Integer).MAX_VALUE&quot;).getValue(int.class); System.out.println(result3 == Integer.MAX_VALUE); //类静态方法调用 int result4 = parser.parseExpression(&quot;T(Integer).parseInt('1')&quot;).getValue(int.class); System.out.println(result4); } 输出 class java.lang.String true true 1 对于 java.lang 包里的可以直接使用 “T(String)” 访问；其他包必须是类全限定名；可以进行静态字段访问如“T(Integer).MAX_VALUE”；也可以进行静态方法访问如“T(Integer).parseInt('1')”。 类实例化 类实例化同样使用 java 关键字 “new”，类名必须是全限定名，但 java.lang 包内的类型除外，如 String、Integer。 @Test public void testConstructorExpression() { ExpressionParser parser = new SpelExpressionParser(); String result1 = parser.parseExpression(&quot;new String('路人甲java')&quot;).getValue(String.class); System.out.println(result1); Date result2 = parser.parseExpression(&quot;new java.util.Date()&quot;).getValue(Date.class); System.out.println(result2); } 实例化完全跟 Java 内方式一样，运行输出 路人甲java Tue Aug 03 20:22:43 CST 2020 instanceof 表达式 SpEL 支持 instanceof 运算符，跟 Java 内使用同义；如 “'haha' instanceof T(String)” 将返回 true。 @Test public void testInstanceOfExpression() { ExpressionParser parser = new SpelExpressionParser(); Boolean value = parser.parseExpression(&quot;'路人甲' instanceof T(String)&quot;).getValue(Boolean.class); System.out.println(value); } 输出 true 变量定义及引用 变量定义通过 EvaluationContext 接口的 setVariable(variableName, value) 方法定义；在表达式中使用&quot;#variableName&quot;引用；除了引用自定义变量，SpE 还允许引用根对象及当前上下文对象，使用&quot;#root&quot;引用根对象，使用&quot;#this&quot;引用当前上下文对象； @Test public void testVariableExpression() { ExpressionParser parser = new SpelExpressionParser(); EvaluationContext context = new StandardEvaluationContext(); context.setVariable(&quot;name&quot;, &quot;路人甲java&quot;); context.setVariable(&quot;lesson&quot;, &quot;Spring系列&quot;); //获取name变量，lesson变量 String name = parser.parseExpression(&quot;#name&quot;).getValue(context, String.class); System.out.println(name); String lesson = parser.parseExpression(&quot;#lesson&quot;).getValue(context, String.class); System.out.println(lesson); //StandardEvaluationContext构造器传入root对象，可以通过#root来访问root对象 context = new StandardEvaluationContext(&quot;我是root对象&quot;); String rootObj = parser.parseExpression(&quot;#root&quot;).getValue(context, String.class); System.out.println(rootObj); //#this用来访问当前上线文中的对象 String thisObj = parser.parseExpression(&quot;#this&quot;).getValue(context, String.class); System.out.println(thisObj); } 输出 路人甲java Spring系列 我是root对象 我是root对象 使用 “#variable” 来引用在 EvaluationContext 定义的变量；除了可以引用自定义变量，还可以使用 “#root” 引用根对象，“#this”引用当前上下文对象，此处 “#this” 即根对象。 自定义函数 目前只支持类静态方法注册为自定义函数；SpEL 使用 StandardEvaluationContext 的 registerFunction 方法进行注册自定义函数，其实完全可以使用 setVariable 代替，两者其实本质是一样的； @Test public void testFunctionExpression() throws SecurityException, NoSuchMethodException { //定义2个函数,registerFunction和setVariable都可以，不过从语义上面来看用registerFunction更恰当 StandardEvaluationContext context = new StandardEvaluationContext(); Method parseInt = Integer.class.getDeclaredMethod(&quot;parseInt&quot;, String.class); context.registerFunction(&quot;parseInt1&quot;, parseInt); context.setVariable(&quot;parseInt2&quot;, parseInt); ExpressionParser parser = new SpelExpressionParser(); System.out.println(parser.parseExpression(&quot;#parseInt1('3')&quot;).getValue(context, int.class)); System.out.println(parser.parseExpression(&quot;#parseInt2('3')&quot;).getValue(context, int.class)); String expression1 = &quot;#parseInt1('3') == #parseInt2('3')&quot;; boolean result1 = parser.parseExpression(expression1).getValue(context, boolean.class); System.out.println(result1); } 此处可以看出 “registerFunction” 和“setVariable”都可以注册自定义函数，但是两个方法的含义不一样，推荐使用 “registerFunction” 方法注册自定义函数。 运行输出 3 3 true 表达式赋值 使用Expression#setValue方法可以给表达式赋值 @Test public void testAssignExpression1() { Object user = new Object() { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;$classname{&quot; + &quot; + name + '\\'' + '}'; } }; { //user为root对象 ExpressionParser parser = new SpelExpressionParser(); EvaluationContext context = new StandardEvaluationContext(user); parser.parseExpression(&quot;#root.name&quot;).setValue(context, &quot;路人甲java&quot;); System.out.println(parser.parseExpression(&quot;#root&quot;).getValue(context, user.getClass())); } { //user为变量 ExpressionParser parser = new SpelExpressionParser(); EvaluationContext context = new StandardEvaluationContext(); context.setVariable(&quot;user&quot;, user); parser.parseExpression(&quot;#user.name&quot;).setValue(context, &quot;路人甲java&quot;); System.out.println(parser.parseExpression(&quot;#user&quot;).getValue(context, user.getClass())); } } 运行输出 $classname{name='路人甲java'} $classname{name='路人甲java'} 对象属性存取及安全导航表达式 对象属性获取非常简单，即使用如 “a.property.property” 这种点缀式获取，SpEL 对于属性名首字母是不区分大小写的；SpEL 还引入了 Groovy 语言中的安全导航运算符“(对象 | 属性)?. 属性”，用来避免 “?.” 前边的表达式为 null 时抛出空指针异常，而是返回 null；修改对象属性值则可以通过赋值表达式或 Expression 接口的 setValue 方法修改。 public static class Car { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;Car{&quot; + &quot; + name + '\\'' + '}'; } } public static class User { private Car car; public Car getCar() { return car; } public void setCar(Car car) { this.car = car; } @Override public String toString() { return &quot;User{&quot; + &quot;car=&quot; + car + '}'; } } @Test public void test5() { User user = new User(); EvaluationContext context = new StandardEvaluationContext(); context.setVariable(&quot;user&quot;, user); ExpressionParser parser = new SpelExpressionParser(); //使用.符号，访问user.car.name会报错，原因：user.car为空 try { System.out.println(parser.parseExpression(&quot;#user.car.name&quot;).getValue(context, String.class)); } catch (EvaluationException | ParseException e) { System.out.println(&quot;出错了：&quot; + e.getMessage()); } //使用安全访问符号?.，可以规避null错误 System.out.println(parser.parseExpression(&quot;#user?.car?.name&quot;).getValue(context, String.class)); Car car = new Car(); car.setName(&quot;保时捷&quot;); user.setCar(car); System.out.println(parser.parseExpression(&quot;#user?.car?.toString()&quot;).getValue(context, String.class)); } 运行输出 出错了：EL1007E: Property or field 'name' cannot be found on null null Car{name='保时捷'} 对象方法调用 对象方法调用更简单，跟 Java 语法一样；如 “'haha'.substring(2,4)” 将返回“ha”；而对于根对象可以直接调用方法； Bean 引用 SpEL 支持使用 “@” 符号来引用 Bean，在引用 Bean 时需要使用 BeanResolver 接口实现来查找 Bean，Spring 提供 BeanFactoryResolver 实现。 @Test public void test6() { DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); User user = new User(); Car car = new Car(); car.setName(&quot;保时捷&quot;); user.setCar(car); factory.registerSingleton(&quot;user&quot;, user); StandardEvaluationContext context = new StandardEvaluationContext(); context.setBeanResolver(new BeanFactoryResolver(factory)); ExpressionParser parser = new SpelExpressionParser(); User userBean = parser.parseExpression(&quot;@user&quot;).getValue(context, User.class); System.out.println(userBean); System.out.println(userBean == factory.getBean(&quot;user&quot;)); } 运行输出 User{car=Car{name='保时捷'}} true 集合相关表达式 内联 List 从 Spring3.0.4 开始支持内联 List，使用 {表达式，……} 定义内联 List，如 “{1,2,3}” 将返回一个整型的 ArrayList，而 “{}” 将返回空的 List，对于字面量表达式列表，SpEL 会使用 java.util.Collections.unmodifiableList 方法将列表设置为不可修改。 @Test public void test7() { ExpressionParser parser = new SpelExpressionParser(); //将返回不可修改的空List List&lt;Integer&gt; result2 = parser.parseExpression(&quot;{}&quot;).getValue(List.class); //对于字面量列表也将返回不可修改的List List&lt;Integer&gt; result1 = parser.parseExpression(&quot;{1,2,3}&quot;).getValue(List.class); Assert.assertEquals(new Integer(1), result1.get(0)); try { result1.set(0, 2); } catch (Exception e) { e.printStackTrace(); } //对于列表中只要有一个不是字面量表达式，将只返回原始List， //不会进行不可修改处理 String expression3 = &quot;{{1+2,2+4},{3,4+4}}&quot;; List&lt;List&lt;Integer&gt;&gt; result3 = parser.parseExpression(expression3).getValue(List.class); result3.get(0).set(0, 1); System.out.println(result3); //声明二维数组并初始化 int[] result4 = parser.parseExpression(&quot;new int[2]{1,2}&quot;).getValue(int[].class); System.out.println(result4[1]); //定义一维数组并初始化 int[] result5 = parser.parseExpression(&quot;new int[1]&quot;).getValue(int[].class); System.out.println(result5[0]); } 输出 java.lang.UnsupportedOperationException at java.util.Collections$UnmodifiableList.set(Collections.java:1311) at com.javacode2018.spel.SpelTest.test7(SpelTest.java:315) [[1, 6], [3, 8]] 2 0 内联数组 和 Java 数组定义类似，只是在定义时进行多维数组初始化。 int[][][] result4 = parser.parseExpression(&quot;new int[1][2][3]{{1}{2}{3}}&quot;).getValue(int[][][].class); 集合，字典元素访问 SpEL 目前支持所有集合类型和字典类型的元素访问，使用 “集合[索引]” 访问集合元素，使用 “map[key]” 访问字典元素； //SpEL内联List访问 int result1 = parser.parseExpression(&quot;{1,2,3}[0]&quot;).getValue(int.class); //SpEL目前支持所有集合类型的访问 Collection&lt;Integer&gt; collection = new HashSet&lt;Integer&gt;(); collection.add(1); collection.add(2); EvaluationContext context2 = new StandardEvaluationContext(); context2.setVariable(&quot;collection&quot;, collection); int result2 = parser.parseExpression(&quot;#collection[1]&quot;).getValue(context2, int.class); //SpEL对Map字典元素访问的支持 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put(&quot;a&quot;, 1); EvaluationContext context3 = new StandardEvaluationContext(); context3.setVariable(&quot;map&quot;, map); int result3 = parser.parseExpression(&quot;#map['a']&quot;).getValue(context3, int.class); 列表，字典，数组元素修改 可以使用赋值表达式或 Expression 接口的 setValue 方法修改； @Test public void test8() { ExpressionParser parser = new SpelExpressionParser(); //修改list元素值 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); list.add(2); EvaluationContext context1 = new StandardEvaluationContext(); context1.setVariable(&quot;collection&quot;, list); parser.parseExpression(&quot;#collection[1]&quot;).setValue(context1, 4); int result1 = parser.parseExpression(&quot;#collection[1]&quot;).getValue(context1, int.class); System.out.println(result1); //修改map元素值 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put(&quot;a&quot;, 1); EvaluationContext context2 = new StandardEvaluationContext(); context2.setVariable(&quot;map&quot;, map); parser.parseExpression(&quot;#map['a']&quot;).setValue(context2, 4); Integer result2 = parser.parseExpression(&quot;#map['a']&quot;).getValue(context2, int.class); System.out.println(result2); } 输出 4 4 集合投影 在 SQL 中投影指从表中选择出列，而在 SpEL 指根据集合中的元素中通过选择来构造另一个集合，该集合和原集合具有相同数量的元素；SpEL 使用 “（list|map）.![投影表达式]” 来进行投影运算： @Test public void test9() { ExpressionParser parser = new SpelExpressionParser(); //1.测试集合或数组 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(4); list.add(5); EvaluationContext context1 = new StandardEvaluationContext(); context1.setVariable(&quot;list&quot;, list); Collection&lt;Integer&gt; result1 = parser.parseExpression(&quot;#list.![#this+1]&quot;).getValue(context1, Collection.class); result1.forEach(System.out::println); System.out.println(&quot;------------&quot;); //2.测试字典 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put(&quot;a&quot;, 1); map.put(&quot;b&quot;, 2); EvaluationContext context2 = new StandardEvaluationContext(); context2.setVariable(&quot;map&quot;, map); List&lt;Integer&gt; result2 = parser.parseExpression(&quot;#map.![value+1]&quot;).getValue(context2, List.class); result2.forEach(System.out::println); } 对于集合或数组使用如上表达式进行投影运算，其中投影表达式中 “#this” 代表每个集合或数组元素，可以使用比如 “#this.property” 来获取集合元素的属性，其中 “#this” 可以省略。 Map 投影最终只能得到 List 结果，如上所示，对于投影表达式中的 “#this” 将是 Map.Entry，所以可以使用 “value” 来获取值，使用 “key” 来获取键。 集合选择 在 SQL 中指使用 select 进行选择行数据，而在 SpEL 指根据原集合通过条件表达式选择出满足条件的元素并构造为新的集合，SpEL 使用 “(list|map).?[选择表达式]”，其中选择表达式结果必须是 boolean 类型，如果 true 则选择的元素将添加到新集合中，false 将不添加到新集合中。 @Test public void test10() { ExpressionParser parser = new SpelExpressionParser(); //1.测试集合或数组 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); list.add(4); list.add(5); list.add(7); EvaluationContext context1 = new StandardEvaluationContext(); context1.setVariable(&quot;list&quot;, list); Collection&lt;Integer&gt; result1 = parser.parseExpression(&quot;#list.?[#this&gt;4]&quot;).getValue(context1, Collection.class); result1.forEach(System.out::println); System.out.println(&quot;------------&quot;); } 输出 5 7 对于集合或数组选择，如 “#collection.?[#this&gt;4]” 将选择出集合元素值大于 4 的所有元素。选择表达式必须返回布尔类型，使用 “#this” 表示当前元素。 //2.测试字典 Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put(&quot;a&quot;, 1); map.put(&quot;b&quot;, 2); map.put(&quot;c&quot;, 3); EvaluationContext context2 = new StandardEvaluationContext(); context2.setVariable(&quot;map&quot;, map); Map&lt;String, Integer&gt; result2 = parser.parseExpression(&quot;#map.?[key!='a']&quot;).getValue(context2, Map.class); result2.forEach((key, value) -&gt; { System.out.println(key + &quot;:&quot; + value); }); System.out.println(&quot;------------&quot;); List&lt;Integer&gt; result3 = parser.parseExpression(&quot;#map.?[key!='a'].![value+1]&quot;).getValue(context2, List.class); result3.forEach(System.out::println); 输出 b:2 c:3 ------------ 3 4 对于字典选择，如 “#map.?[#this.key != 'a']” 将选择键值不等于”a”的，其中选择表达式中 “#this” 是 Map.Entry 类型，而最终结果还是 Map，这点和投影不同；集合选择和投影可以一起使用，如 “#map.?[key != 'a'].![value+1]” 将首先选择键值不等于”a”的，然后在选出的 Map 中再进行 “value+1” 的投影。 表达式模板 模板表达式就是由字面量与一个或多个表达式块组成。每个表达式块由 “前缀 + 表达式 + 后缀” 形式组成，如 “${1+2}” 即表达式块。在前边我们已经介绍了使用 ParserContext 接口实现来定义表达式是否是模板及前缀和后缀定义。在此就不多介绍了，如 “Error ${#v0} ${#v1}” 表达式表示由字面量 “Error ”、模板表达式“#v0”、模板表达式“#v1” 组成，其中 v0 和 v1 表示自定义变量，需要在上下文定义。 解析表达式的时候需要指定模板，模板通过ParserContext接口来定义 public interface ParserContext { //是否是模板 boolean isTemplate(); //模板表达式前缀 String getExpressionPrefix(); //模板表达式后缀 String getExpressionSuffix(); } 有个子类，我们直接可以拿来用：TemplateParserContext。 @Test public void test11() { //创建解析器 SpelExpressionParser parser = new SpelExpressionParser(); //创建解析器上下文 ParserContext context = new TemplateParserContext(&quot;%{&quot;, &quot;}&quot;); Expression expression = parser.parseExpression(&quot;你好:%{#name},我们正在学习:%{#lesson}&quot;, context); //创建表达式计算上下文 EvaluationContext evaluationContext = new StandardEvaluationContext(); evaluationContext.setVariable(&quot;name&quot;, &quot;路人甲java&quot;); evaluationContext.setVariable(&quot;lesson&quot;, &quot;spring高手系列!&quot;); //获取值 String value = expression.getValue(evaluationContext, String.class); System.out.println(value); } 运行输出 你好:路人甲java,我们正在学习:spring高手系列! 在 Bean 定义中使用 spel 表达式 xml 风格的配置 SpEL 支持在 Bean 定义时注入，默认使用 “#{SpEL 表达式}” 表示，其中 “#root” 根对象默认可以认为是 ApplicationContext，只有 ApplicationContext 实现默认支持 SpEL，获取根对象属性其实是获取容器中的 Bean。 如： &lt;bean&gt; &lt;constructor-arg value=&quot;#{' World!'}&quot;/&gt; &lt;/bean&gt; &lt;bean&gt; &lt;constructor-arg value=&quot;#{'Hello'}#{world}&quot;/&gt; &lt;/bean&gt; &lt;bean&gt; &lt;constructor-arg value=&quot;#{'Hello' + world}&quot;/&gt; &lt;/bean&gt; &lt;bean&gt; &lt;constructor-arg value=&quot;#{'Hello' + @world}&quot;/&gt; &lt;/bean&gt; 模板默认以前缀 “#{” 开头，以后缀 “}” 结尾，且不允许嵌套，如 “#{'Hello'#{world}}” 错误，如 “#{'Hello' + world}” 中“world”默认解析为 Bean。当然可以使用 “@bean” 引用了。 是不是很简单，除了 XML 配置方式，Spring 还提供一种注解方式 @Value，接着往下看吧。 注解风格的配置 基于注解风格的 SpEL 配置也非常简单，使用 @Value 注解来指定 SpEL 表达式，该注解可以放到字段、方法及方法参数上。 测试 Bean 类如下，使用 @Value 来指定 SpEL 表达式： public class SpELBean { @Value(&quot;#{'Hello' + world}&quot;) private String value; } 在 Bean 定义中 SpEL 的问题 如果有同学问 “#{我不是 SpEL 表达式}” 不是 SpEL 表达式，而是公司内部的模板，想换个前缀和后缀该如何实现呢？ 我们使用 BeanFactoryPostProcessor 接口提供 postProcessBeanFactory 回调方法，它是在 IoC 容器创建好但还未进行任何 Bean 初始化时被 ApplicationContext 实现调用，因此在这个阶段把 SpEL 前缀及后缀修改掉是安全的，具体代码如下： package com.javacode2018.spel.test1; import org.springframework.beans.BeansException; import org.springframework.beans.factory.config.BeanExpressionResolver; import org.springframework.beans.factory.config.BeanFactoryPostProcessor; import org.springframework.beans.factory.config.ConfigurableListableBeanFactory; import org.springframework.context.expression.StandardBeanExpressionResolver; import org.springframework.stereotype.Component; @Component public class SpelBeanFactoryPostProcessor implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { BeanExpressionResolver beanExpressionResolver = beanFactory.getBeanExpressionResolver(); if (beanExpressionResolver instanceof StandardBeanExpressionResolver) { StandardBeanExpressionResolver resolver = (StandardBeanExpressionResolver) beanExpressionResolver; resolver.setExpressionPrefix(&quot;%{&quot;); resolver.setExpressionSuffix(&quot;}&quot;); } } } 上测试代码 package com.javacode2018.spel.test1; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component public class LessonModel { @Value(&quot;你好,%{@name},%{@msg}&quot;) private String desc; @Override public String toString() { return &quot;LessonModel{&quot; + &quot;desc='&quot; + desc + '\\'' + '}'; } } @name：容器中 name 的 bean @msg：容器中 msg 的 bean 下面我们来个配置类，顺便定义 name 和 msg 这 2 个 bean，顺便扫描上面 2 个配置类 package com.javacode2018.spel.test1; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @ComponentScan @Configuration public class MainConfig { @Bean public String name() { return &quot;路粉&quot;; } @Bean public String msg() { return &quot;欢迎和我一起学习java各种技术！&quot;; } } 测试用例 @Test public void test12() { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.register(MainConfig.class); context.refresh(); LessonModel lessonModel = context.getBean(LessonModel.class); System.out.println(lessonModel); } 运行输出 LessonModel{desc='你好,路粉,欢迎和我一起学习java各种技术！'} 总结 Spel 功能还是比较强大的，可以脱离 spring 环境独立运行 spel 可以用在一些动态规则的匹配方面，比如监控系统中监控规则的动态匹配；其他的一些条件动态判断等等 本文内容比较长，建议大家把案例都敲一遍，可以设置一些断点去研究一下源码，有问题的，欢迎大家留言交流。 案例源码 https://gitee.com/javacode2018/spring-series ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"}],"title":"【转载】玩转Spring中强大的spel表达式！","feature":"","link":"https://xuyj1111.github.io/HSVGIODQf/","stats":{"text":"32 min read","time":1869000,"words":6875,"minutes":32},"date":"2023-02-16 16:45:50","dateFormat":"2023-02-16"},{"content":" 注解@JsonIgnoreProperties, by 弄玉x 一、jackson 的 mavern 依赖 &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; 二、使用的背景 springboot 项目中定义了很多类，我们在 rest 返回中直接返回或者在返回对象中使用这些类，spring 已经使用 jackson 自动帮我们完成这些的 to json。但是有时候自动转的 json 内容太多，或者格式不符合我们的期望，因此需要调整类的 to json 过程，或者说希望自定义类的 json 过程。 三、@JsonProperty 1、概念： 此注解用于属性上，作用是把该属性的名称序列化为另外一个名称，如把 trueName 属性序列化为 name，@JsonProperty(“name”)。 对属性名称重命名，比如在很多场景下 Java 对象的属性是按照规范的驼峰书写，但在数据库设计时使用的是下划线连接方式，此处在进行映射的时候就可以使用该注解。 2、用法 例如：使用该注解将以下表结构转化为 Javabean： public class CustomerInfo{ private int id; //使用 @JsonProperty注解将表结构中的字段映射到实体类中 @JsonProperty(&quot;customer_name&quot;) private String customerName; @JsonProperty(&quot;customer_id&quot;) private String customerId; @JsonProperty(&quot;product_id&quot;) private String productId; @JsonProperty(&quot;source_address&quot;) private String sourceAddress; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getCustomerName() { return customerName; } public void setCustomerName(String customerName) { this.customerName = customerName; } public String getCustomerId() { return customerId; } public void setCustomerId(String customerId) { this.customerId = customerId; } public String getProductId() { return productId; } public void setProductId(String productId) { this.productId = productId; } public String getSourceAddress() { return sourceAddress; } public void setSourceAddress(String sourceAddress) { this.sourceAddress = sourceAddress; } } 四、@JsonIgnore 1、概念 用于属性或者方法上（最好是属性上），用来完全忽略被注解的字段和方法对应的属性，即便这个字段或方法可以被自动检测到或者还有其他的注解，一般标记在属性或者方法上，返回的 json 数据即不包含该属性。 2、用法 使用情景：需要把一个 List 转换成 json 格式的数据传递给前台。但实体类中基本属性字段的值都存储在快照属性字段中。此时我可以在业务层中做处理，把快照属性字段的值赋给实体类中对应的基本属性字段。最后，我希望返回的 json 数据中不包含这两个快照字段，那么在实体类中快照属性上加注解 @JsonIgnore，那么最后返回的 json 数据，将不会包含 customerId 和 productId 两个属性值。 public class CustomerInfo { private int id; //使用 @JsonIgnore注解在生成json数据时，忽略该字段 private String customerName; @JsonIgnore private String customerId; @JsonIgnore private String productId; private String sourceAddress; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getCustomerName() { return customerName; } public void setCustomerName(String customerName) { this.customerName = customerName; } public String getCustomerId() { return customerId; } public void setCustomerId(String customerId) { this.customerId = customerId; } public String getProductId() { return productId; } public void setProductId(String productId) { this.productId = productId; } public String getSourceAddress() { return sourceAddress; } public void setSourceAddress(String sourceAddress) { this.sourceAddress = sourceAddress; } } 五、@JsonIgnoreProperties 1、概念： 是类注解，作用是 json 序列化时将 java bean 中的一些属性忽略掉，序列化和反序列化都受影响。 2、用法： @JsonIgnoreProperties(ignoreUnknown = true)，将这个注解写在类上之后，就会忽略类中不存在的字段。 使用 @Data @JsonIgnoreProperties(value = {&quot;fullName&quot;, &quot;comment&quot;}) public class User { private String id; private String name; private String fullName; private String comment; private String mail; @JsonIgnore private String address; @JsonFormat(timezone = &quot;GMT+8&quot;, pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) private Date regDate; private Date reg2Date; } 说明：User 类的 fullName 和 comment 字段会被 @JsonIgnoreProperties 注解忽略。address 字段会被 @JsonIgnore 注解忽略。regDate 会按照 @JsonFormat(timezone = “GMT+8”, pattern = “yyyy-MM-dd HH:mm:ss”) 进行格式转。 我们的 controller 示例代码： @ApiOperation(value = &quot;按用户id删除&quot;, notes=&quot;private&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;userId&quot;, defaultValue = &quot;2&quot;, value = &quot;userID&quot;, required = true, dataType = &quot;string&quot;, paramType = &quot;path&quot;), }) @DeleteMapping(value = &quot;/users/{userId}&quot;, produces = &quot;application/json;charset=UTF-8&quot;) public User delUser(@PathVariable String userId) { User user = (User)userSvc.deleteById(userId); log.info(&quot;rest del user={} by id={}&quot;, user, userId); return user; } 可以看到返回的对象是 User，然后 comment、fullName、address 属性被忽略了，regDate 的格式进行转换。 六、@JsonFormat 1、概念： 用于属性或者方法上（最好是属性上），可以方便的把 Date 类型直接转化为我们想要的模式。 2、用法： @JsonFormat(pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;) private Date updateTime; 七、@JsonSerialize 用于属性或者 getter 方法上，用于在序列化时嵌入我们自定义的代码，比如序列化一个 double 时在其后面限制两位小数点。 八、@JsonDeserialize 用于属性或者 setter 方法上，用于在反序列化时可以嵌入我们自定义的代码，类似于上面的 @JsonSerialize。 九、@JsonInclude 属性值为 null 的不参与序列化。例子：@JsonInclude(Include.NON_NULL)。 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"}],"title":"【转载】jackson 的几个注解","feature":"","link":"https://xuyj1111.github.io/Kj_kWSjDE/","stats":{"text":"6 min read","time":316000,"words":1199,"minutes":6},"date":"2023-02-15 10:26:58","dateFormat":"2023-02-15"},{"content":" 参考文章：HttpMessageConverter 消息转换器，by 小二上酒8 My GitHub Demo ：CLICK HERE HttpMessageConverter下有多个HttpMessageConverter，HttpMessageConverter 是 SpringMVC 中提供的一个策略接口，它是一个消息转换器类，Spring Mvc 中就是由 HttpMessageConverter 负责转换 HTTP 的请求和响应 默认情况下，Spring Boot 会自动加载如下消息类型转换器👇 StringHttpMessageConverter负责读取字符串格式的数据和写出二进制格式的数据(当返回值是或者接受值是 String 类型时，是由这个处理) MappingJacksonHttpMessageConverter负责读取和写入 json 格式的数据；(当返回值是对象或者List，就由这个处理) ByteArrayHttpMessageConverter负责读取二进制格式的数据和写出二进制格式的数据； FormHttpMessageConverter负责读取 form 提交的数据（能读取的数据格式为 application/x-www-form-urlencoded，不能读取 multipart/form-data 格式数据）；负责写入 application/x-www-from-urlencoded 和 multipart/form-data 格式的数据； ResourceHttpMessageConverter负责读取资源文件和写出资源文件数据； SourceHttpMessageConverter负责读取和写入 xml 中 javax.xml.transform.Source 定义的数据； Jaxb2RootElementHttpMessageConverter负责读取和写入 xml 标签格式的数据； AtomFeedHttpMessageConverter负责读取和写入 Atom 格式的数据； RssChannelHttpMessageConverter负责读取和写入 RSS 格式的数据； 执行流程👇 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】HttpMessageConverters 类","feature":"","link":"https://xuyj1111.github.io/nZRRBCWiX/","stats":{"text":"2 min read","time":74000,"words":326,"minutes":2},"date":"2023-02-14 14:32:10","dateFormat":"2023-02-14"},{"content":" Mysql的4种事务特性、4种隔离级别、7种传播行为，by lu2hiqiang 4 种事务特性 原子性（Atomicity）：事务包含的所有操作要么全部执行成功，要么全部失败回滚，强调的是事务的不可分割性； 一致性（Consistency）： 事务执行前和执行后必须处于一次性状态，事务执行前后数据的完整性必须保持一致，例如：转账； 隔离性（isolation）：一个事务执行过程中不应受到其他事务的影响，即多个并发事务之间要相互隔离 持久性（Durability）：事务一旦结束，数据就持久到数据库 5 种隔离级别 如果不考虑事务的隔离性会引发以下安全性问题： 脏读：一个事务读取到了另一个事务还未提交的数据； 不可重复读：一个事务读取到了另一个事务已经提交的 update 的数据导致多次查询结果不一致；【行锁】 幻读：一个事务读取到另一个事务已经提交的 insert 的数据导致多次查询结果不一致；【表锁】 解决读问题：设置隔离级别（4 种） # 查看当前全局事务隔离级别: # MySQL5.6 及其更早的版本 select @@global.tx_isolation; # MySQL5.7 及更高版本 select @@global.transaction_isolation; # 修改 MySQL 全局默认事务隔离级别 # MySQL5.6 及其更早的版本 set global tx_isolation='read-uncommitted'; set global tx_isolation='read-committed'; set global tx_isolation='repeatable-read'; set global tx_isolation='serializable'; # MySQL5.7 及更高版本 set global transaction_isolation='read-uncommitted'; set global transaction_isolation='read-committed'; set global transaction_isolation='repeatable-read'; set global transaction_isolation='serializable'; 未提交读（read uncommited）: 所有事务都可以看到其他未提交事务的执行结果；此隔离级别很少在实际应用中使用，可能会发生脏读、不可重复读、幻读；【读不加锁；写瞬间加读锁，事务结束释放】 已提交读（read commited）：事务只能看到已经提交事务所改变的数据，可能会发生不可重复读、幻读；【读瞬间加读锁，读完之后立即释放；写瞬间加写锁，事务结束才释放】 可重复读（repeatable read）：mysql 默认隔离级别，同一事务的多个实例在并发读取数据时，会看到同样的数据行，可能会发生幻读；（注： InnoDB 和 Falcon 存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题）【读瞬间加读锁，事务完成之后才释放锁；写瞬间加写锁，事务结束才释放】 串行化（serializable）：最高的隔离级别，它强制事务顺序，使之不可能相互冲突，可避免三种读，但可能导致大量的超时现象和锁竞争。【读瞬间加读锁；写瞬间加写锁】 只有串行化是表锁 ，其他都是行锁 注意：隔离性与并发性，此消彼长。 事务隔离级别不同实际是因为生产 read view 的时间不同导致的 7 种传播行为 PROPAGATION_REQUIRED 支持当前事务，如果不存在 就新建一个 (默认) PROPAGATION_SUPPORTS 支持当前事务，如果不存在，就不使用事务 PROPAGATION_MANDATORY 支持当前事务，如果不存在，抛出异常 保证没有在同一个事务中 PROPAGATION_REQUIRES_NEW 如果有事务存在，挂起当前事务，创建一个新的事务 PROPAGATION_NOT_SUPPORTED 以非事务方式运行，如果有事务存在，挂起当前事务 PROPAGATION_NEVER 以非事务方式运行，如果有事务存在，抛出异常 PROPAGATION_NESTED 如果当前事务存在，则嵌套事务执行 在分布式系统中一般先执行不会对外界造成影响的操作（可以回滚的操作），后执行不可控，或者不能回滚的操作，不可回滚操作应当有且只有一个。 数据库量大的优化 原因：随着数据量的增多，sql 语句效率下降。 解决方案：按照这个顺序优化；加索引，表分区（分流），分库分表、读写分离； 分区的优点： 不影响业务 放不同磁盘上 可以备份、回复，逐步进行； ","tags":[{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【转载】Mysql的4种事务特性、4种隔离级别、7种传播行为","feature":"","link":"https://xuyj1111.github.io/bJ4DMMqiI/","stats":{"text":"4 min read","time":225000,"words":1049,"minutes":4},"date":"2023-02-12 15:26:47","dateFormat":"2023-02-12"},{"content":" 参考文章：Spring——事务注解@Transactional，by 七海健人 @Transactional 来源于 Spring，用来管理事务。该注解属于 Spring 的声明式事务，还有一种是编程式事务，编程式对代码具有侵入性，不推荐使用。 注解的使用 可以用在接口、类、方法： 接口：不推荐，Spring AOP 使用 CGLib 时，注解会失效 类：生效于类中所有 public 方法 方法：类和方法同时配置，方法注解会覆盖类注解 注解属性 public @interface Transactional { /** * 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 */ @AliasFor(&quot;transactionManager&quot;) String value() default &quot;&quot;; /** * 同上。 */ @AliasFor(&quot;value&quot;) String transactionManager() default &quot;&quot;; /** * 事务的传播行为，默认值为 REQUIRED。 */ Propagation propagation() default Propagation.REQUIRED; /** * 事务的隔离规则，默认值采用 DEFAULT。 */ Isolation isolation() default Isolation.DEFAULT; /** * 事务超时时间。 */ int timeout() default TransactionDefinition.TIMEOUT_DEFAULT; /** * 是否只读事务 */ boolean readOnly() default false; /** * 用于指定能够触发事务回滚的异常类型。 */ Class&lt;? extends Throwable&gt;[] rollbackFor() default {}; /** * 同上，指定类名。 */ String[] rollbackForClassName() default {}; /** * 用于指定不会触发事务回滚的异常类型 */ Class&lt;? extends Throwable&gt;[] noRollbackFor() default {}; /** * 同上，指定类名 */ String[] noRollbackForClassName() default {}; } 失效的场景 注解在非 public 方法上 注解在 final 方法上 同一个类中，某方法调用事务方法 解决办法一：事务方法新写一个 Service，然后类中注入使用 解决方法二：当前类中，注入自己，参考Spring——循环依赖&amp;三级缓存 解决办法三：使用AopContext.currentProxy()获取当前类的代理对象 @Servcie public class ServiceA { public void save(User user) { queryData1(); queryData2(); ((ServiceA)AopContext.currentProxy()).doSave(user); } @Transactional(rollbackFor=Exception.class) public void doSave(User user) { addData1(); updateData2(); } } 事务方法所在类，没有被 Spring 管理，例如没有加@Service注解 数据库存储引擎不支持事务：mysql 的 myisam 不支持事务 两个方法不在同一线程中，即是两个不同的事务 Spring 中的传播方式和隔离级别 七种传播方式👇 // 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值 1. Propagation.REQUIRED // 创建一个新的事务，如果当前存在事务，则把当前事务挂起 2. Propagation.REQUIRES_NEW // 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行 3. Propagation.SUPPORTS // 以非事务方式运行，如果当前存在事务，则把当前事务挂起 4. Propagation.NOT_SUPPORTED // 以非事务方式运行，如果当前存在事务，则抛出异常 5. Propagation.NEVER // 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常 6. Propagation.MANDATORY /* 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行 如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED */ 7. Propagation.NESTED 五种隔离级别👇 // 使用后端数据库默认的隔离级别 对于MYSQL来说就是可重复读 1. Isolation.DEFAULT // 是最低的隔离级别，允许读取尚未提交的数据变更(会出现脏读,不可重复读)，基本不使用 2. Isolation.READ_UNCOMMITTED // 允许读取并发事务已经提交的数据(会出现不可重复读和幻读) 3. Isolation.READ_COMMITTED // 事物开启后，对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改(会出现幻读) 4. Isolation.REPEATABLE_READ // 最高的隔离级别，完全服从ACID的隔离级别，也是最慢的事务隔离级别，因为它通常是通过完全锁定事务相关的数据库表来实现的 5. Isolation.SERIALIZABLE ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】@Transactional注解","feature":"","link":"https://xuyj1111.github.io/q62qJQE0u/","stats":{"text":"4 min read","time":215000,"words":944,"minutes":4},"date":"2023-02-12 14:56:34","dateFormat":"2023-02-12"},{"content":" 参考文章 mysql锁（全局锁、表锁、行锁、页锁、排他锁、共享锁，by ζ荷逸こ Mysql中的共享锁和排他锁，by Bronze5 mysql间隙锁、表锁、行锁，读锁（共享锁）、写锁（排他锁），意向锁，by ?Bad guy? 读操作 = 查询 = select 写操作 = 更新 = update、delete、insert 乐观锁是通过代码控制的，不需要数据库加锁 基本思想：在并发环境下，通过无阻塞的方式避免冲突，提高系统并发性。 做法：在数据库记录上添加版本号（时间戳）来实现。当一个线程修改数据前，检查数据的版本号是否过时，若过时，说明被其他线程修改，不作操作，重新读取数据；若未过时，进行操作并修改版本号 缺点：并发量过大时，会导致大量失败和重试，影响性能。实际应用中需要与其他技术结合 以下介绍四种悲观锁👇 表锁 行锁 共享锁：又称“读锁”、“S锁” 排他锁：又称“写锁”、“X锁” MySQL 中，需要注意存储引擎，InnoDB 和 MyISAM 对锁的支持不同。本文中“共享锁”和“排他锁”的介绍是在 InnoDB 环境下 表锁和行锁 表锁和行锁是范围，即可能是共享锁锁住了表/行，也可能是排他锁锁住了表/行 存储引擎的不同，加锁也不同👇 MyISAM：查询时，自动给涉及的所有表加读锁；更新时，自动给涉及的表加写锁。这个过程不需要用户干预【仅支持表锁】 InnoDB：【支持表锁，行锁】 需要使用加锁语句（见共享锁和排他锁） 不使用加锁语句为前提，select 时不会加锁，update、delete、insert 时会自动加排他锁 不走索引，行锁会自动升级表锁 共享锁 特性👇 多个事务都对某一数据集/表加了共享锁，仅支持读 写操作会自动加排他锁，共享锁会阻塞排他锁，因此不支持写操作 只有当前事务加共享锁，当前事务读写都支持 加锁语句👇 -- 对表加共享锁 LOCK TABLE table_name READ; -- 对数据集加共享锁 SELECT * FROM table_name WHERE ... lock in share mode; -- 释放所有锁 UNLOCK TABLE; 场景👇 事务1 为某一数据集加共享锁，事务2 也对该数据集加共享锁。 两事务都可以读 事务1 对该数据集执行更新操作，会等待；若对其他数据集更新，不会等待【更新操作会带来排他锁，共享锁会阻塞排他锁，因此等待；其他数据集没有锁，因此不等待】 事务1 等待情况下，提交事务2，事务1 更新操作执行完成【提交事务2，只剩下事务1，因此读写都支持】 p.s. 在步骤1 之后，事务2 执行 name 条件的修改语句，则不管步骤2 对哪个数据集更新操作，都会等待【name不是索引字段，行锁会升级成表锁】 事务1 begin; select * from t1 where id = 1 lock in share mode; update t1 set data = JSON_REPLACE(data, '$.key1', 'value1') where id = 1; commit; 事务2 begin; select * from t1 where id = 1 lock in share mode; &lt;!-- name 条件的修改语句👇 --&gt; -- select * from t1 where name = 'haha' lock in share mode; commit; 排他锁 特性👇 仅支持当前获取排他锁的事务，进行读写操作 写操作会自动加上排他锁 加锁语句👇 -- 对表加排他锁 LOCK TABLE table_name WRITE; -- 对数据集加排他锁 SELECT * FROM table_name WHERE ... for update; -- 释放所有锁 UNLOCK TABLE; LOCK TABLES 和 UNLOCK TABLES LOCK TABLES可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止 UNLOCK TABLES可以释放当前线程获得的任何锁定。当前线程执行另一个LOCK TABLES时， 或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁 注意事项👇 在用LOCK TABLES对 InnoDB 表加锁时，要把 AUTOCOMMIT 设为 0，否则 MySQL 不会给表加锁 UNLOCK TABLES会隐含的提交事务，即COMMIT COMMIT或ROLLBACK并不能释放用LOCK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【MySQL】各种锁的介绍","feature":"","link":"https://xuyj1111.github.io/jkZZ_73nV/","stats":{"text":"4 min read","time":239000,"words":1076,"minutes":4},"date":"2023-02-10 15:12:17","dateFormat":"2023-02-10"},{"content":" jdk 中的可重入锁有synchronized和ReentrantLock 可重入锁，也称为递归锁。一个持有锁的线程，在释放锁之前，如果再次访问了该同步锁的其他方法，这个线程不需要再次竞争锁，只需要记录重入次数。重入锁的设计目的是为了解决死锁的问题 p.s. 以 synchronized 举例，若一个 synchronized 方法1 调用 synchronized 方法2，两方法的锁都是同一个，则某线程执行方法1时，会一并执行方法2，并不会因为方法1拿了锁，方法2没有而不执行 synchronized synchronized 有四种用法： 修饰实例方法 修饰静态方法 修饰实例方法的代码块 修饰静态方法的代码块 synchronized 代码块的参数：this表示当前类对象（静态方法中不能用）；xxx.class表示类本身；还可以传入其他参数 // 修饰实例方法：锁的是类对象 public synchronized void printHello() { System.out.println(&quot;hello&quot;); } // 修饰静态方法：锁的是类本身 public static synchronized void printHi() { System.out.println(&quot;hi&quot;); } // 修饰实例方法的代码块 public void printHello() { synchronized (this) { System.out.println(&quot;hello&quot;); } } // 修饰静态方法的代码块 public static void printHi() { synchronized (MultithreadDemo.class) { System.out.println(&quot;hello&quot;); } } ReentrantLock ReentrantLock 类实现了 Lock接口，除此以外还有其他实现类👇 常用方法 lock()：等待锁，无视中断 lockInterruptibly()：等待锁，考虑中断。中断会抛出 InterruptedException tryLock(long timeout, TimeUnit unit)：指定时间等待锁，考虑中断。指定时间内获得锁返回 true，否则 false，中断会抛出 InterruptedException tryLock()：直接获取锁。成功 true，否则 false，相当于tryLock(0, TimeUnit unit) unlock()：解锁。必须有持有锁的线程执行，否则抛出 IllegalMonitorStateException 为了避免死锁，unlock()最好放在 finally 中 ReentrantLock 是可重入锁，因此一个线程可能多次加锁，但是unlock()执行一次解锁一次，因此加几次锁，就要解锁几次 lock() 和 unlock() 的简单使用👇 private Lock lock = new ReentrantLock(); public void run () { lock.lock(); try { for (int i = 0; i &lt; 5; i++) System.out.println(Thread.currentThread().getName() + &quot;:&quot; + i); } finally { lock.unlock(); } } lock()、lockInterruptibly()、tryLock(long timeout, TimeUnit unit) 在线程中断情况下的表现👇 ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(new Runnable() { @Override public void run() { try { lock.lock(); System.out.println(&quot;t1拿到锁&quot;); Thread.sleep(1000L); System.out.println(&quot;t1执行结束&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } }); Thread t2 = new Thread(new Runnable() { @Override public void run() { boolean flag = true; try { System.out.println(&quot;t2等待拿锁&quot;); // ****************** start ********************** // lock.lock(); // lock.lockInterruptibly(); flag = lock.tryLock(200, TimeUnit.MILLISECONDS); // ****************** end ********************** if (flag) { System.out.println(&quot;t2拿到锁&quot;); System.out.println(&quot;t2执行结束&quot;); } else { System.out.println(&quot;指定时间内没有拿到锁，over&quot;); } } catch (Exception e) { e.printStackTrace(); } finally { if (flag) { lock.unlock(); } } } }); t1.start(); // 保证 t1 拿到锁 Thread.sleep(10L); t2.start(); // 保证 t2 在等待锁 Thread.sleep(10L); // 若隐藏线程中断语句，t2 正常等待锁 或 指定时间内等待 t2.interrupt(); // 在测试类中需要保持运行一会 Thread.sleep(2000L); 其他方法 int getHoldCount()：当前锁的加锁次数，如果无线程持有锁就返回0 int getQueueLength()：当前竞争此锁队列长度 int getWaitQueueLength(Condition condition)：当前锁等待队列长度。需要与Condition联合使用 boolean isFair()：是否是公平锁 boolean isLocked()：当前锁是否处于锁定状态 boolean isHeldByCurrentThread()：当前锁是否被当前线程持有 boolean hasWaiters(Condition condition)：当前condition是否有线程在等待，需要与Condition联合使用 boolean hasQueuedThread(Thread thread)：目标线程是否在这个锁的竞争队列中 boolean hasQueuedThreads()：是否有线程在当前锁的竞争队列中 两者区别 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】jdk 中的可重入锁","feature":"","link":"https://xuyj1111.github.io/DoVZDpDB6/","stats":{"text":"4 min read","time":230000,"words":907,"minutes":4},"date":"2023-02-09 14:25:27","dateFormat":"2023-02-09"},{"content":" 从 MySQL5.7.8 开始，支持字段使用 JSON 数据类型 JSON 数据类型（官网） JSON 函数目录（官网） 开始 创建表和字段 CREATE TABLE t1 ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `data` JSON, PRIMARY KEY (`id`) ); JSON 类型支持“JSON对象”和“JSON数组”👇 JSON 对象：{&quot;k1&quot;: &quot;value&quot;, &quot;k2&quot;: 10} JSON 数组：[&quot;abc&quot;, 10, null, true, false] JSON 数组和 JSON 对象允许互相嵌套👇 [99, {&quot;id&quot;: &quot;HK500&quot;, &quot;cost&quot;: 75.99}, [&quot;hot&quot;, &quot;cold&quot;]] {&quot;k1&quot;: &quot;value&quot;, &quot;k2&quot;: [10, 20]} 插入数据示例👇INSERT INTO t1(data) VALUES('{&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;}');INSERT INTO t1(data) VALUES('[&quot;a&quot;, 1, &quot;2015-07-27 09:43:47.000000&quot;] '); JSON 赋值给变量 JSON 值可以赋值给变量，但不是 JSON 类型，而是转换为字符串SET @j = JSON_OBJECT('key', 'value');转换的字符串具有字符集“utf8mb4”，排序规则“utf8mb4_bin”。执行SELECT CHARSET(@j),COLLATION(@j)可查看utf8mb4_bin 是二进制排序规则，所以 JSON 值区分大小写。null、true、false在 JSON 中必须是小写字母 mysql&gt; SELECT JSON_VALID('null'), JSON_VALID('Null'); +--------------------+--------------------+ | JSON_VALID('null') | JSON_VALID('Null') | +--------------------+--------------------+ | 1 | 0 | +--------------------+--------------------+ 创建 JSON JSON_ARRAY([val[, val] ...]) 创建 JSON 数据👇 mysql&gt; SELECT JSON_ARRAY(1, &quot;abc&quot;, NULL, TRUE, CURTIME()); +---------------------------------------------+ | JSON_ARRAY(1, &quot;abc&quot;, NULL, TRUE, CURTIME()) | +---------------------------------------------+ | [1, &quot;abc&quot;, null, true, &quot;10:47:25.000000&quot;] | +---------------------------------------------+ JSON_OBJECT([key, val[, key, val] ...]) 创建 JSON 对象👇 mysql&gt; SELECT JSON_OBJECT('id', 87, 'name', 'carrot'); +-----------------------------------------+ | JSON_OBJECT('id', 87, 'name', 'carrot') | +-----------------------------------------+ | {&quot;id&quot;: 87, &quot;name&quot;: &quot;carrot&quot;} | +-----------------------------------------+ JSON_QUOTE(string) 生成 JSON 字符串文字👇 mysql&gt; SELECT JSON_QUOTE('null'), JSON_QUOTE('&quot;null&quot;'), JSON_QUOTE('[1, 2, 3]'); +--------------------+----------------------+-------------------------+ | JSON_QUOTE('null') | JSON_QUOTE('&quot;null&quot;') | JSON_QUOTE('[1, 2, 3]') | +--------------------+----------------------+-------------------------+ | &quot;null&quot; | &quot;\\&quot;null\\&quot;&quot; | &quot;[1, 2, 3]&quot; | +--------------------+----------------------+-------------------------+ 合并 JSON JSON_MERGE(json_doc, json_doc[, json_doc] ...)👇 -- 合并多个数组 mysql&gt; SELECT JSON_MERGE('[1, 2]', '[&quot;a&quot;, &quot;b&quot;]', '[true, false]'); +-----------------------------------------------------+ | JSON_MERGE('[1, 2]', '[&quot;a&quot;, &quot;b&quot;]', '[true, false]') | +-----------------------------------------------------+ | [1, 2, &quot;a&quot;, &quot;b&quot;, true, false] | +-----------------------------------------------------+ -- 合并多个对象 mysql&gt; SELECT JSON_MERGE('{&quot;a&quot;: 1, &quot;b&quot;: 2}', '{&quot;c&quot;: 3, &quot;a&quot;: 4}'); +----------------------------------------------------+ | JSON_MERGE('{&quot;a&quot;: 1, &quot;b&quot;: 2}', '{&quot;c&quot;: 3, &quot;a&quot;: 4}') | +----------------------------------------------------+ | {&quot;a&quot;: [1, 4], &quot;b&quot;: 2, &quot;c&quot;: 3} | +----------------------------------------------------+ -- 合并多个值 mysql&gt; SELECT JSON_MERGE('1', '2'); +----------------------+ | JSON_MERGE('1', '2') | +----------------------+ | [1, 2] | +----------------------+ -- 合并数组和对象 mysql&gt; SELECT JSON_MERGE('[10, 20]', '{&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;}'); +------------------------------------------------+ | JSON_MERGE('[10, 20]', '{&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;}') | +------------------------------------------------+ | [10, 20, {&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;}] | +------------------------------------------------+ 若 JSON 数据中的 key 相同，也会合并数据 mysql&gt; INSERT INTO t1(`data`) VALUES &gt; ('{&quot;x&quot;: 17, &quot;x&quot;: &quot;red&quot;}'), &gt; ('{&quot;x&quot;: 17, &quot;x&quot;: &quot;red&quot;, &quot;x&quot;: [3, 5, 7]}'); mysql&gt; SELECT c1 FROM t1; +-----------+ | c1 | +-----------+ | {&quot;x&quot;: 17} | | {&quot;x&quot;: 17} | +-----------+ 搜索 JSON JSON_EXTRACT(json_doc, path[, path] ...)👇 -- 根据索引，查找 value mysql&gt; SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]'); +--------------------------------------------+ | JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]') | +--------------------------------------------+ | 20 | +--------------------------------------------+ mysql&gt; SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]', '$[0]'); +----------------------------------------------------+ | JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]', '$[0]') | +----------------------------------------------------+ | [20, 10] | +----------------------------------------------------+ mysql&gt; SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[2][*]'); +-----------------------------------------------+ | JSON_EXTRACT('[10, 20, [30, 40]]', '$[2][*]') | +-----------------------------------------------+ | [30, 40] | +-----------------------------------------------+ -- 根据 key，查找 value mysql&gt; SELECT JSON_EXTRACT('{&quot;id&quot;: 14, &quot;name&quot;: &quot;Aztalan&quot;}', '$.name'); +---------------------------------------------------------+ | JSON_EXTRACT('{&quot;id&quot;: 14, &quot;name&quot;: &quot;Aztalan&quot;}', '$.name') | +---------------------------------------------------------+ | &quot;Aztalan&quot; | +---------------------------------------------------------+ JSON_KEYS(json_doc[, path])👇 -- 未指定 path，默认返回第一层的 keys mysql&gt; SELECT JSON_KEYS('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}'); +---------------------------------------+ | JSON_KEYS('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}') | +---------------------------------------+ | [&quot;a&quot;, &quot;b&quot;] | +---------------------------------------+ -- 指定 path，返回指定节点下的 keys mysql&gt; SELECT JSON_KEYS('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}', '$.b'); +----------------------------------------------+ | JSON_KEYS('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}', '$.b') | +----------------------------------------------+ | [&quot;c&quot;] | +----------------------------------------------+ JSON_SEARCH(json_doc, one_or_all, search_str[, escape_char[, path] ...]) 返回 JSON 文档中匹配字符串的路径👇 mysql&gt; SET @j = '[&quot;abc&quot;, [{&quot;k&quot;: &quot;10&quot;}, &quot;def&quot;], {&quot;x&quot;:&quot;abc&quot;}, {&quot;y&quot;:&quot;bcd&quot;}]'; -- one 表示只匹配第一个 mysql&gt; SELECT JSON_SEARCH(@j, 'one', 'abc'); +-------------------------------+ | JSON_SEARCH(@j, 'one', 'abc') | +-------------------------------+ | &quot;$[0]&quot; | +-------------------------------+ -- all 表示匹配所有 mysql&gt; SELECT JSON_SEARCH(@j, 'all', 'abc'); +-------------------------------+ | JSON_SEARCH(@j, 'all', 'abc') | +-------------------------------+ | [&quot;$[0]&quot;, &quot;$[2].x&quot;] | +-------------------------------+ -- search_str 可以只用 &quot;%&quot; 和 &quot;_&quot; 通配符 mysql&gt; SELECT JSON_SEARCH(@j, 'all', '%a%'); +-------------------------------+ | JSON_SEARCH(@j, 'all', '%a%') | +-------------------------------+ | [&quot;$[0]&quot;, &quot;$[2].x&quot;] | +-------------------------------+ -- escape_char：指定转义字符，必须是常量（为空或一个字符）。参数值为 NULL 或 不存在时，默认 &quot;\\&quot; -- 按照格式，必须要指定转义字符，才可以使用 path，path 即指定匹配的路径 mysql&gt; SELECT JSON_SEARCH(@j, 'all', '%b%', '', '$[3]'); +-------------------------------------------+ | JSON_SEARCH(@j, 'all', '%b%', '', '$[3]') | +-------------------------------------------+ | &quot;$[3].y&quot; | +-------------------------------------------+ 插入/修改/删除 JSON JSON_INSERT(json_doc, path, val[, path, val] ...)👇 mysql&gt; SET @j = '{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}'; mysql&gt; SELECT JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]'); +----------------------------------------------------+ | JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]') | +----------------------------------------------------+ | {&quot;a&quot;: 1, &quot;b&quot;: [2, 3], &quot;c&quot;: &quot;[true, false]&quot;} | +----------------------------------------------------+ -- 上方的&quot;[true, false]&quot;为字符串，若要转为 JSON，需要用到 CAST 函数 mysql&gt; SELECT JSON_INSERT(@j, '$.a', 10, '$.c', CAST('[true, false]' AS JSON)); +------------------------------------------------------------------+ | JSON_INSERT(@j, '$.a', 10, '$.c', CAST('[true, false]' AS JSON)) | +------------------------------------------------------------------+ | {&quot;a&quot;: 1, &quot;b&quot;: [2, 3], &quot;c&quot;: [true, false]} | +------------------------------------------------------------------+ JSON_REPLACE(json_doc, path, val[, path, val] ...) 替换JSON文档中的现有值并返回结果👇 -- 文档中存在则替换，不存在忽略 mysql&gt; SELECT JSON_REPLACE('{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}', '$.a', 10, '$.c', '[true, false]'); +---------------------------------------------------------------------------+ | JSON_REPLACE('{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}', '$.a', 10, '$.c', '[true, false]') | +---------------------------------------------------------------------------+ | {&quot;a&quot;: 10, &quot;b&quot;: [2, 3]} | +---------------------------------------------------------------------------+ JSON_SET(json_doc, path, val[, path, val] ...) 在JSON文档中插入或更新数据并返回结果👇 -- JSON_SET = JSON_INSERT + JSON_REPLACE mysql&gt; SELECT JSON_SET('{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}', '$.a', 10, '$.c', '[true, false]'); +-----------------------------------------------------------------------+ | JSON_SET('{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}', '$.a', 10, '$.c', '[true, false]') | +-----------------------------------------------------------------------+ | {&quot;a&quot;: 10, &quot;b&quot;: [2, 3], &quot;c&quot;: &quot;[true, false]&quot;} | +-----------------------------------------------------------------------+ JSON_REMOVE(json_doc, path[, path] ...) 删除并返回结果👇 mysql&gt; SELECT JSON_REMOVE('[&quot;a&quot;, [&quot;b&quot;, &quot;c&quot;], &quot;d&quot;]', '$[1]'); +-----------------------------------------------+ | JSON_REMOVE('[&quot;a&quot;, [&quot;b&quot;, &quot;c&quot;], &quot;d&quot;]', '$[1]') | +-----------------------------------------------+ | [&quot;a&quot;, &quot;d&quot;] | +-----------------------------------------------+ 其他 JSON 函数 JSON_TYPE(json_val) 判断值的类型👇 mysql&gt; SELECT JSON_TYPE('[&quot;a&quot;, &quot;b&quot;, 1]'), -&gt; JSON_TYPE('{&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;}'), -&gt; JSON_TYPE('&quot;hello&quot;'); +----------------------------+---------------------------------------------------+----------------------+ | JSON_TYPE('[&quot;a&quot;, &quot;b&quot;, 1]') | JSON_TYPE('{&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;}') | JSON_TYPE('&quot;hello&quot;') | +----------------------------+---------------------------------------------------+----------------------+ | ARRAY | OBJECT | STRING | +----------------------------+---------------------------------------------------+----------------------+ JSON_LENGTH(json_doc[, path]) 返回 JSON 文档的长度👇 -- 未指定 path，默认返回第一层的长度 mysql&gt; SELECT JSON_LENGTH('[1, 2, {&quot;a&quot;: 3}]'); +---------------------------------+ | JSON_LENGTH('[1, 2, {&quot;a&quot;: 3}]') | +---------------------------------+ | 3 | +---------------------------------+ mysql&gt; SELECT JSON_LENGTH('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}'); +-----------------------------------------+ | JSON_LENGTH('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}') | +-----------------------------------------+ | 2 | +-----------------------------------------+ -- 指定 path，返回指定节点下的长度 mysql&gt; SELECT JSON_LENGTH('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}', '$.b'); +------------------------------------------------+ | JSON_LENGTH('{&quot;a&quot;: 1, &quot;b&quot;: {&quot;c&quot;: 30}}', '$.b') | +------------------------------------------------+ | 1 | +------------------------------------------------+ JSON_VALID(val) 校验JSON值是否有效👇 mysql&gt; SELECT JSON_VALID('{&quot;a&quot;: 1}'), JSON_VALID('hello'), JSON_VALID('&quot;hello&quot;'); +------------------------+---------------------+-----------------------+ | JSON_VALID('{&quot;a&quot;: 1}') | JSON_VALID('hello') | JSON_VALID('&quot;hello&quot;') | +------------------------+---------------------+-----------------------+ | 1 | 0 | 1 | +------------------------+---------------------+-----------------------+ JSON 新运算符 插入数据INSERT INTO t1(data) VALUES (JSON_OBJECT(&quot;mascot&quot;, &quot;Our mascot is a dolphin named \\&quot;Sakila\\&quot;.&quot;));可以根据 key 查找匹配项SELECT data-&gt;&quot;$.mascot&quot; FROM t1，用到了&quot;-&gt;&quot;列路径运算符 -- 这种写法会与每条数据都匹配查询一次，未找到的返回 null mysql&gt; SELECT data-&gt;&quot;$.mascot&quot; FROM t1; +---------------------------------------------+ | data-&gt;&quot;$.mascot&quot; | +---------------------------------------------+ | NULL | | NULL | | &quot;Our mascot is a dolphin named \\&quot;Sakila\\&quot;.&quot; | +---------------------------------------------+ -- 使用子查询解决上面问题，必须要把子查询命名为派生表【也可以使用 JSON_EXTRACT 函数】 mysql&gt; SELECT data-&gt;&quot;$.mascot&quot; FROM (SELECT data FROM t1 WHERE `id` = 3) AS tt; +---------------------------------------------+ | data-&gt;&quot;$.mascot&quot; | +---------------------------------------------+ | &quot;Our mascot is a dolphin named \\&quot;Sakila\\&quot;.&quot; | +---------------------------------------------+ 使用&quot;-&gt;&gt;&quot;内联路径运算符 mysql&gt; SELECT data-&gt;&gt;&quot;$.mascot&quot; FROM t1; +-----------------------------------------+ | data-&gt;&gt;&quot;$.mascot&quot; | +-----------------------------------------+ | NULL | | NULL | | Our mascot is a dolphin named &quot;Sakila&quot;. | +-----------------------------------------+ ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【MySQL】JSON 数据类型","feature":"","link":"https://xuyj1111.github.io/vA57Xu34i/","stats":{"text":"10 min read","time":581000,"words":1796,"minutes":10},"date":"2023-02-08 14:39:28","dateFormat":"2023-02-08"},{"content":" MySQL PREPARE预处理，by Kevin崔 MySQL PREPARE 预处理技术意义在于，是为了减轻服务器压力的一种技术。 就是说绝大多数情况下，某需求某一条 SQL 语句可能会被反复调用执行，或者每次执行的时候只有个别的值不同。 比如： SELECT 的 WHERE 子句值不同； UPDATE 的 SET 子句值不同； INSERT 的 VALUES 值不同； 如果每次都需要经过上面的词法语义解析、语句优化、制定执行计划等，则效率就明显下降。 1. 预处理 MySQL 提供了对服务器端准备语句的支持，就叫预处理。 这种支持利用了高效的客户机 / 服务器二进制协议，使用带有参数值占位符的预编译语句有以下好处: 减少每次执行语句时解析语句的开销。通常，数据库应用程序处理大量几乎相同的语句，只对子句中的字面值或变量值进行更改，例如用于查询和删除的 WHERE、用于更新的 SET 和用于插入的 values。 防止 SQL 注入攻击。参数值可以包含未转义的 SQL 引号和分隔符。 预处理接口 应用程序中的预处理语句 可以通过客户端编程接口使用服务器端准备好的语句，包括用于 C 程序的 MySQL C API 客户端库，用于 Java 程序的 MySQL Connector/J，以及用于使用。NET 技术的程序的 MySQL Connector/NET。例如，C API 提供了一组函数调用，这些函数调用构成了它的预编译语句 API 2.SQL 脚本中的准备语句 还有一个用于预处理语句的替代 SQL 接口。但不需要编程，在 SQL 级别直接可用，可以在任何可以将 SQL 语句发送到要执行的服务器的程序中使用它，例如 mysql 客户端程序。 2. 预处理应用方式 预处理语句的 SQL 语法基于三个 SQL 语句: PREPARE 语句准备执行。 EXECUTE 执行一条预处理语句。 DEALLOCATE PREPARE 释放一个预处理语句。 A. 例子： 预处理语句无法跨 SESSION 操作： mysql&gt;CREATE TABLE `t1` ( `id` int NOT NULL, NAME varchar(20), KEY `idx_id` (`id`) ) ENGINE=InnoDB ; mysql&gt;INSERT INTO t1(id,name) values(1,'A'),(2,'B'),(3,'C'),(4,'D'),(5,'E'),(6,'F'); #设定预处理语句 mysql&gt;PREPARE stmt1 FROM 'SELECT * FROM t1 WHERE a=? '; #设置传递变量 mysql&gt;SET @a = 8; #执行语句 mysql&gt;EXECUTE stmt1 USING @a; #释放预处理语句 mysql&gt;DEALLOCATE PREPAR stmt1; B. 预处理对执行计划变化跟踪 通过观察 status 指标 Select_scan（执行全表搜索查询的数量）变化判断是否会受到数据量变更的影响。 预处理 sql 语句随着数据量的变化执行计划也在变更。 C. 存储过程包含预处理 预处理语句在存储的例程中创建预处理语句，则在存储的例程结束时不会释放该语句。 DELIMITER // DROP PROCEDURE IF EXISTS proc_prepared; CREATE PROCEDURE proc_prepared() BEGIN DECLARE a INT; DECLARE i INT; PREPARE stmt1 FROM 'SELECT * FROM t1 WHERE id&gt;? '; SET @a = 5; EXECUTE stmt1 USING @a; END // DELIMITER ; call proc_prepared(); 存储过程之后单独调用预处理语句，返回结果集：说明预处理没有销毁 SET @a = 5; EXECUTE stmt1 USING @a; +----+------+ | id | NAME | +----+------+ | 6 | F | 。。。 存储过程之后单独调用预处理语句，返回结果集：说明预处理没有销毁 SET @a = 5; EXECUTE stmt1 USING @a; +----+------+ | id | NAME | +----+------+ | 6 | F | 。。。 D. 通过 profile 查看解析语句的开销 通过 profile 各种语句执行时间，解析语句花费的时间都在 0.01 秒以内。可以忽略不计。 所以目前在预处理方面上没有发现明显的优势。 3. 总结 预编译初始的作用： 提高效率：事先解析、检查、编译等工作。 提高安全性：预防 SQL 注入 局限性和实际效果： 预处理因为局限在 session 级别，现在无法体现真正的价值。因为 mysql GA 版本没有线程池概念，每个链接就是每个 session 解析编译语句的开销 基本对于 mysql 环境来说忽略不计 执行计划也是随着数据量而变化的。 从局限性和实际效果来看，目前没有发挥应有的功能。不适合声场环境中使用。 ","tags":[{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【转载】MySQL预处理","feature":"","link":"https://xuyj1111.github.io/yZ13CWGFl/","stats":{"text":"5 min read","time":253000,"words":1105,"minutes":5},"date":"2023-02-05 17:52:26","dateFormat":"2023-02-05"},{"content":"MySQL 分为内连接和外连接： 内连接：inner join、cross join、join【三者在 MySQL 中是相同的】 隐式：SELECT [cols_list] from 表 1,表 2 where [condition] 显式：SELECT [cols_list] from 表 1 INNER JOIN 表 2 ON [关联条件] where [其他筛选条件] 外连接：left join、right join、full join【MySQL 不支持 full join，可以使用left join union right join替代】 表连接的关联条件有三种： WHERE ON：与 JOIN 一起使用 USING：与 JOIN 一起使用，要求两个表的字段名相同，且关联条件为相等 笛卡尔积👇 定义：表连接的结果，是多个表的乘积 产生的原因是：缺少关联条件或者关联条件不准确【外连接必须写关联条件，否则语法错误】 SELECT name,Java FROM student,souce; SELECT name,Java FROM student INNER JOIN souce; SELECT name,Java FROM student JOIN souce; SELECT name,Java FROM student CROSS JOIN souce; 各种连接图示👇 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【MySQL】表的各种连接","feature":"","link":"https://xuyj1111.github.io/oGPyoz9xf/","stats":{"text":"1 min read","time":57000,"words":223,"minutes":1},"date":"2023-02-05 17:26:52","dateFormat":"2023-02-05"},{"content":"新建注解 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface SimpleAnno { String name(); int age(); } 其中使用到两个注解： @Retention：定义注解的生命周期 @Target：表示注解作用范围，超过这个作用范围，编译的时候就会报错 使用注解 在需要使用的类上添加注解👇 @Data @SimpleAnno(name = &quot;王铁柱&quot;, age = 59) public class TestAnnoDTO { private String name; private int age; } 使用对象前可以获取注解上的值，根据值做不用的操作，一般写在 factory 类中👇 @Test public void testAnnotation() { TestAnnoDTO testAnnoDTO = new TestAnnoDTO(); Class&lt;? extends TestAnnoDTO&gt; aClass = testAnnoDTO.getClass(); SimpleAnno annotation = aClass.getAnnotation(SimpleAnno.class); if (Objects.isNull(annotation)) { System.out.println(&quot;该类没有使用 [SimpleAnno] 注解&quot;); } else { testAnnoDTO.setName(annotation.name()); testAnnoDTO.setAge(annotation.age()); System.out.println(testAnnoDTO); } } ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】自定义注解","feature":"","link":"https://xuyj1111.github.io/TjTPK-Axn/","stats":{"text":"1 min read","time":49000,"words":180,"minutes":1},"date":"2023-02-05 16:53:03","dateFormat":"2023-02-05"},{"content":" show engines;显示系统所支持的引擎类型 show variables like 'default_storage_engine%';查看系统的默认存储引擎 set default_storage_engine = 存储引擎;设置默认存储引擎，但重启客户端后，仍为 InnoDB show variables like 'log_error';查看运行错误日志的目录 show variables like 'log_bin';查看是否开启 binlog select @@tx_isolation;查看当前会话隔离级别 select @@global.tx_isolation;查看系统隔离级别 set session transaction isolation level 隔离级别;设置当前会话隔离级别 set global transaction isolation level 隔离级别;设置当前会话隔离级别 字符集👇 查看数据库编码 SHOW CREATE DATABASE db_name; 查看表编码 SHOW CREATE TABLE tbl_name; 查看字段编码 SHOW FULL COLUMNS FROM tbl_name; 修改数据库字符集 ALTER DATABASE db_name DEFAULT CHARACTER SET character_name [COLLATE ...]; 把表默认的字符集和所有字符列（CHAR,VARCHAR,TEXT）改为新的字符集 ALTER TABLE tbl_name CONVERT TO CHARACTER SET character_name [COLLATE ...] 示例：ALTER TABLE logtest CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci; 只是修改表的默认字符集 ALTER TABLE tbl_name DEFAULT CHARACTER SET character_name [COLLATE...]; 示例：ALTER TABLE logtest DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 修改字段的字符集 ALTER TABLE tbl_name CHANGE c_name c_name CHARACTER SET character_name [COLLATE ...]; 示例：ALTER TABLE logtest CHANGE title title VARCHAR(100) CHARACTER SET utf8 COLLATE utf8_general_ci; 表👇 修改表名 rename table old_table to new_table； 插入另一个表数据 insert into table02 select * from table01; 复制表数据和表结构 create table table02 select * from table01; 只复制表结构 create table table02 like table01; 修改密码👇 update mysql.user set authentication_string=password('123456') where user='root' and Host ='localhost'; flush privileges;刷新权限 创建库👇 CREATE DATABASE [IF NOT EXISTS] &lt;数据库名&gt; [[DEFAULT] CHARACTER SET &lt;字符集名&gt;] [[DEFAULT] COLLATE &lt;校对规则名&gt;]; 示例：CREATE DATABASE IF NOT EXISTS mygame CHARACTER SET utf8mb4 COLLATE utf8mb4_german2_ci; ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【Mysql】一些命令","feature":"","link":"https://xuyj1111.github.io/dMqKAi0Gt/","stats":{"text":"2 min read","time":114000,"words":416,"minutes":2},"date":"2023-02-03 16:21:36","dateFormat":"2023-02-03"},{"content":"docker 简单介绍 docker 是一个应用容器引擎，重要概念有以下几点： 镜像 容器 数据卷 镜像和容器的关系，与面向对象中的类和实例一样，镜像是静态的定义，容器是镜像运行的实体。容器可以被创建、启动、停止、删除、暂停等，容器本质上是进程。 首先需要有以下几个概念： docker 在 Windows 和 Mac 上都有桌面端了，此时的 Windows/Mac 则被称为“宿主机” 容器存储层的生命周期和容器一样，容器停止，则存储层丢失 容器之间是相互独立的，不能直接访问 数据卷的作用则是用来将容器数据持久化，和使容器之间、容器和宿主机之间数据传输 安装 Docker Desktop 傻瓜安装 配置镜像加速器网址，使用阿里镜像，需要登录自己账号 命令 docker [command] --help帮助命令 镜像命令👇 docker images列出所有镜像 docker inspect 镜像名查看镜像的详细信息 docker search 镜像名 或者 仓库名称/镜像名查询镜像【默认官方仓库名为 library】 docker pull 镜像名 或者 仓库名称/镜像名下载镜像 docker rmi [可选参数] 镜像名 [镜像名...] -f：强制删除 容器命令👇 docker ps列出所有正在运行的容器 docker inspect 容器id 或 容器名查看容器的详细信息 docker run [可选参数] 镜像名 [向启动容器中传入的命令] -i：打开标容器的标准输入接口，通常-id或-it使用 -d：后台运行 -t：容器启动后进入命令行 --name：为创建的容器命名，默认随机，不支持中文字符 -v：目录映射，宿主机目录:容器目录，在宿主机上修改会同步到容器上【持久化】 一个容器可以映射多个目录 两个容器映射同一个目录，实现两个容器的数据交换 -p：端口映射，宿主机端口:容器端口 docker exec [可选参数] 容器名 /bin/bash -i：打开标容器的标准输入接口，通常-id或-it使用 -d：后台运行 -t：容器启动后进入命令行 docker start 容器id 或 容器名启动容器 docker stop 容器id 或 容器名停止容器 docker rm [可选参数] 容器id 或 容器名 [IMAGE...]删除容器【运行状态删除失败，停止状态才可删除】 -f：强制删除 -l：移除容器间的网络连接，并非容器本身 -v：删除与容器关联的卷 在 centos 容器中执行hostnamectl set-hostname 名字命令，想要修改主机名，出现报错，然后以特权模式再生成容器解决docker run -itd --name master01 --privileged 容器名 /usr/sbin/init，参考文档docker run --privileged参数 数据卷容器👇 可以使用docker run命令的-v参数启动数据卷容器，实现容器和宿主机的数据共享 docker run -itd --name=c3 -v /volume centos /bin/bash 按照格式，应该是“宿主机目录:容器目录”，此处写法省略/volume，即/volume:/volume 还可以使用--volumes-from参数指定父容器 docker run -itd --name=c1 --volumes-from c3 centos /bin/bash 再启动 c2 docker run -itd --name=c2 --volumes-from c3 centos /bin/bash，实现下图结构：c1 和 c2 实际上都关联到宿主机，即使 c3 挂了，c1、c2、宿主机之间还是能数据共享 镜像制作👇 如果在容器中运行修改了若干文件，并产生了数据，想要传输给别人使用，就需要将容器转换为镜像，但镜像不能直接传输，还需要再将镜像转为压缩文件，接收方收到压缩文件后，还需要解压文件成镜像，才可使用 docker commit 容器id 镜像名称:版本号容器转换为镜像 docker save -o 压缩文件名称 镜像名称:版本号镜像转换为压缩文件 docker load -i 压缩文件名称解压文件成镜像 Dockerfile 文件 需要放在容器的第一层目录，且不能后缀名。Dockerfile 有一套语法，此处不做笔记 kubernetes 作为后端仅了解大概，没有对其深入学习 前情提要 在 docker 容器化技术的发展后，开发过程中对容器的数量逐步增加，进而产生了管理容器的需求。docker 有三剑客： Docker Machine：管理单台或多台主机本身 Docker Compose：管理单主机容器 Docker Swarm：管理多主机容器 其中的 Docker Swarm 和 Kubernetes 角色定位相同，但目前流行使用 Kubernetes。 介绍 详细学习参考https://juejin.cn/post/6952331691524358174#heading-0 安装： 在 Docker Destop 中启动即可 功能： 自动装箱：自动部署容器 自动修复：会重启容器，会重新部署，会重新调度，容器正常才对外提供服务 水平扩展：对容器规模扩大或裁剪 服务发现、负载均衡 滚动更新：一次性或批量式更新 版本回退 热部署 自动存储数据，可以存储在本地、云端等 ...... 资源对象： pod：k8s 管理调度最小的单位。1 个 pod 中可以包含 1 个或多个容器 namespace：集群内部的逻辑分割。pod 在 ns 内 node：k8s 集群中的节点 还有很多资源对象，目前没有对其学习 命令 官方命令文档 kubectl [command] --help帮助命令 kubectl apply -f文件执行文件 kubectl cluster-info dump查看集群信息 kubectl get nodes查看集群节点 config👇 kubectl 默认会从 ~/.kube 目录下查找文件名为 config 的文件，也能通过设置环境变 KUBECONFIG 或者通过设置去指定其它 kubeconfig 文件。kubeconfig就是为访问集群所作的配置，参考文章https://blog.csdn.net/w2009211777/article/details/123798721 增加新集群的配置示例： kubectl config set-cluster jdcloud --server=https://xxx.xxx.xxx.xxx:xxxx --insecure-skip-tls-verify kubectl config set-credentials jdcloud --token=xxxxxx kubectl config set-context devtest --cluster=jdcloud --namespace=devtest --user=jdcloud kubectl config get-contexts查看环境 kubectl config use-context docker-desktop切换环境 pod👇 kubectl describe pod pod名查看pod配置信息 kubectl get pod -o wide：查看更多信息，例如node -n namespace名：查看某 ns 下的 pod kubectl delete pod pod名 -n namespace名 kubectl logs pod名查看pod日志 -n namespace名 -c 容器名：若有多个容器则指定，pod内单个容器可省略 -f：持续看日志 --tail=10：获取最近十条日志 kubectl exec -it pod名 -- /bin/bash进入pod容器（exit退出） -c 容器名：若有多个容器则指定，pod内单个容器可省略 kubectl get pod pod名 -o jsonpath=&quot;{.spec['containers','initContainers'][*].name}&quot; -n namespace名查看pod下所有容器 kubectl get pod,svc查看pod及其ip和端口 namespace👇 kubectl get ns查询所有 namespace kubectl get ns namespace名查询某个 namespace kubectl describe ns namespace名查询某个 namespace 详情 kubectl create ns namespace名创建 namespace kubectl delete ns namespace名删除 namespace 安装 Kubernetes Dashboard 首先需要打开 Docker Desktop，启动 k8s 执行命令，下载 Kubernetes Dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended.yaml 新建用户 新建文件“admin-user.yaml” 文件内容如下，再执行命令kubectl create -f admin-user.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard 绑定用户关系 新建文件“admin-user-role-binding.yaml” 文件内容如下，再执行命令kubectl create -f admin-user-role-binding.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 【若撤销，执行kubectl delete -f 相应的yaml文件】 4. 获取tokenkubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}') 5. 启动服务kubectl proxy 6. 访问 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 7. 选择“Token”，输入上面返回的 token，即可登陆 p.s. 获取 token 的第二个方式： kubectl get secret -n kubernetes-dashboard 使用上图的“admin-user-token-f674x”，拼接命令kubectl describe secret admin-user-token-f674x -n kubernetes-dashboard ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"}],"title":"docker 和 kubernetes 的使用","feature":"","link":"https://xuyj1111.github.io/LmWWpUbJC/","stats":{"text":"9 min read","time":484000,"words":2008,"minutes":9},"date":"2023-02-01 11:34:30","dateFormat":"2023-02-01"},{"content":"标签 所有文章分为两大类，原创和转载 杂记其他知识，与Java、MySQL、Redis等互斥 使用手册为简单介绍某一轮子，如何引入和使用 规范是为自己制定的一些规范 总结、算法、MySQL、Java等标签不做解释 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"规范","slug":"pL5x1IP1J","used":true,"link":"https://xuyj1111.github.io/pL5x1IP1J/"}],"title":"【TOP】小本本的一些介绍","feature":"","link":"https://xuyj1111.github.io/VTHVX8QhD/","stats":{"text":"1 min read","time":15000,"words":75,"minutes":1},"date":"2023-01-30 11:21:32","dateFormat":"2023-01-30"},{"content":"介绍 elastic-job 是基于 Zookeeper、Quartz 开发的分布式定时任务，解决了 Quartz 不支持分布式的问题，使用 Zookeeper 实现分布式。 分布式（集群）的好处是： 分布性：每个服务都可以单独部署，服务之间通过网络通信 伸缩性：可对接点进行软硬件扩容，有一定伸缩性 高可用：集群具有高可用 使用 Zookeeper 的体现 任务的信息存储在 Zookeeper 的节点上 实现选举机制：在多个实例中选择 1 个执行 job 主要的配置信息 namespace：命名空间，用于服务配置。对应 Zk 的首层节点名，上图中的mine_job jobName：job名。对应 Zk 的第二层节点名，上图中的MySimpleJob、MyDataflowJob cron表达式：配置定时 分片数 分片参数：格式分片序列号=参数值，多个用逗号分隔【分片序列号最小0，最大分片数-1】 分片：将 job 分片化，可达到任务并行处理的效果，最大限度提高执行任务的吞吐量。 例如有 2 个实例，分片数 4，则每个实例都获得执行 2 片； 分片参数是用来区分每个分片的作用，例如0=text,1=image,2=radio,3=video，分片0执行时，会把“text”值传入，因此可以在代码里根据参数值的不同做不同的处理 事件追踪功能 监控 job，需要下载elastic-job-lite-console 代码中配置数据源，运行成功会自动生成两张表JOB_EXECUTION_LOG、JOB_STATUS_TRACE_LOG 下载解压elastic-job-lite-console 在下图中的目录下，有两个 start 文件，windows 启动 bat，Linux 启动 sh localhost:8899打开，密码在 conf/auth.properties 文件中，默认 root/root 在“注册中心配置”添加，连接后即可监控 job 代码引入使用 使用yinjihuan的elastic-job，具体介绍见此链接 添加https://jitpack.io maven仓库 引入依赖implementation 'com.github.yinjihuan:elastic-job-spring-boot-starter:1.0.5' application启动类上添加注解@EnableElasticJob application.yml 添加配置 实现SimpleJob或DataflowJob&lt;&gt; SimpleJob 和 DataflowJob 实现 SimpleJob 的任务，只需要在execute方法中写逻辑，且根据 cron 表达式执行； 而 DataflowJob，需要在fetchData方法中读取数据，在processData方法中接收数据并处理。若读取数据为 null，则 job 会停止 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"}],"title":"【Java】elastic-job的使用","feature":"","link":"https://xuyj1111.github.io/GHc69DDuF/","stats":{"text":"3 min read","time":134000,"words":588,"minutes":3},"date":"2023-01-30 11:18:19","dateFormat":"2023-01-30"},{"content":" 虚数的意义，by 阮一峰 有人在 Stack Exchange 问了一个问题： &quot; 我一直觉得虚数（imaginary number）很难懂。 中学老师说，虚数就是 - 1 的平方根。 可是，什么数的平方等于 - 1 呢？计算器直接显示出错！ 直到今天，我也没有搞懂。谁能解释，虚数到底是什么？ 它有什么用？&quot; 帖子的下面，很多人给出了自己的解释，还推荐了一篇非常棒的文章《虚数的图解》。我读后恍然大悟，醍醐灌顶，原来虚数这么简单，一点也不奇怪和难懂！ 下面，我就用自己的语言，讲述我所理解的虚数。 一、什么是虚数？ 首先，假设有一根数轴，上面有两个反向的点：+1 和 - 1。 这根数轴的正向部分，可以绕原点旋转。显然，逆时针旋转 180 度，+1 就会变成 - 1。 这相当于两次逆时针旋转 90 度。 因此，我们可以得到下面的关系式： (+1) * (逆时针旋转 90 度) * (逆时针旋转 90 度) = (-1) 如果把 + 1 消去，这个式子就变为： (逆时针旋转 90 度)^2 = (-1) 将 &quot;逆时针旋转 90 度&quot; 记为 i ： i^2 = (-1) 这个式子很眼熟，它就是虚数的定义公式。 所以，我们可以知道，虚数 i 就是逆时针旋转 90 度，i 不是一个数，而是一个旋转量。 二、复数的定义 既然 i 表示旋转量，我们就可以用 i ，表示任何实数的旋转状态。 将实数轴看作横轴，虚数轴看作纵轴，就构成了一个二维平面。旋转到某一个角度的任何正实数，必然唯一对应这个平面中的某个点。 只要确定横坐标和纵坐标，比如 (1 , i)，就可以确定某个实数的旋转量（45 度）。 数学家用一种特殊的表示方法，表示这个二维坐标：用 + 号把横坐标和纵坐标连接起来。比如，把 (1 , i) 表示成 1 + i 。这种表示方法就叫做复数（complex number），其中 1 称为实数部，i 称为虚数部。 为什么要把二维坐标表示成这样呢，下一节告诉你原因。 三、虚数的作用：加法 虚数的引入，大大方便了涉及到旋转的计算。 比如，物理学需要计算 &quot;力的合成&quot;。假定一个力是 3 + i ，另一个力是 1 + 3i ，请问它们的合成力是多少？ 根据 &quot;平行四边形法则&quot;，你马上得到，合成力就是 (3 + i) + ( 1 + 3i ) = ( 4 + 4i )。 这就是虚数加法的物理意义。 四、虚数的作用：乘法 如果涉及到旋转角度的改变，处理起来更方便。 比如，一条船的航向是 3 + 4i 。 如果该船的航向，逆时针增加 45 度，请问新航向是多少？ 45 度的航向就是 1 + i 。计算新航向，只要把这两个航向 3 + 4i 与 1 + i 相乘就可以了（原因在下一节解释）： (3 + 4i) * ( 1 + i ) = ( -1 + 7i ) 所以，该船的新航向是 -1 + 7i 。 如果航向逆时针增加 90 度，就更简单了。因为 90 度的航向就是 i ，所以新航向等于： (3 + 4i) * i = ( -4 + 3i ) 这就是虚数乘法的物理意义：改变旋转角度。 五、虚数乘法的数学证明 为什么一个复数改变旋转角度，只要做乘法就可以了？ 下面就是它的数学证明，实际上很简单。 任何复数 a + bi，都可以改写成旋转半径 r 与横轴夹角 θ 的形式。 假定现有两个复数 a + bi 和 c + di，可以将它们改写如下： a + bi = r1 * (cosα + isinα) c + di = r2 * (cosβ + isinβ) 这两个复数相乘，(a + bi)( c + di ) 就相当于 r1 * r2 * (cosα + isinα) * ( cosβ + isinβ ) 展开后面的乘式，得到 cosα * cosβ - sinα * sinβ + i(cosα * sinβ + sinα * cosβ) 根据三角函数公式，上面的式子就等于 cos(α+β) + isin(α+β) 所以， (a + bi)( c + di ) ＝ r1 * r2 * ( cos(α+β) + isin(α+β) ) 这就证明了，两个复数相乘，就等于旋转半径相乘、旋转角度相加。 ","tags":[{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"【转载】虚数的意义","feature":"","link":"https://xuyj1111.github.io/ZvPCt8HVu/","stats":{"text":"4 min read","time":237000,"words":1062,"minutes":4},"date":"2022-08-26 16:01:43","dateFormat":"2022-08-26"},{"content":" mac环境 输入命令locate my.cnf，查找mysql的配置文件，并在[mysqld]下写入binlog配置 在系统偏好设置中关闭mysql服务 问题发生：按理说修改了配置文件，重启mysql服务端，即可配置生效。但是mysql启动失败 排查问题： 回退到能启动mysql状态，在客户端执行sqlshow variables like 'log_error'，查找错误日志文件路径（该文件记录了mysql启动和关闭的情况），得到错误日志mysqld: File '/usr/local/mysql/binlog/mysql-bin.index' not found (Errcode: 13 - Permission denied) 根据错误日志判断为权限问题，原因为系统偏好设置中的启动默认为&quot;_mysql&quot;用户，而mysql的大部分文件的权限仅700。在开启binlog服务后，涉及到&quot;_mysql&quot;用户权限不够的文件 关闭mysql服务，按上文在my.cnf文件中开启binlog功能，然后在mysql的bin目录下执行命令sudo mysqld --user=root （提前建立好log_bin和log_bin_index对应的文件夹和文件，权限设置为755，用户用户组为root:_mysql） 到此为手动开启mysql服务 但是系统偏好设置中开启或关闭mysql无法使用，并且失去开机自启动功能 修改系统偏好设置mysql对应的执行文件： /Library/LaunchDaemons/com.oracle.oss.mysql.mysqld.plist（/Library/LaunchDaemons该文件夹中为系统启动时运行文件） .plist文件用vim打开乱码，可通过右键-&gt;快速查看 来查看内容 修改这两处为&quot;root&quot; 修改方式： ​ 一、python（pip install biplist提前安装biplist） from biplist import * file='com.oracle.oss.mysql.mysqld.plist' plist=readPlist(file) plist['ProgramArguments']=['/usr/local/mysql/bin/mysqld', '--user=root', '--basedir=/usr/local/mysql', '--datadir=/usr/local/mysql/data', '--plugin-dir=/usr/local/mysql/lib/plugin', '--log-error=/usr/local/mysql/data/mysqld.local.err', '--pid-file=/usr/local/mysql/data/mysqld.local.pid', '--keyring-file-data=/usr/local/mysql/keyring/keyring', '--early-plugin-load=keyring_file=keyring_file.so'] plist['UserName']='root' writePlist(plist, file) # 下面文章中使用 writePlist(plist, plist_path,binary=False) 来解决中文乱码问题 # https://www.jianshu.com/p/24e5d53b21aa ​ 二、defaults命令：mac自带命令，可读取、修改plist文件 注意⚠️：文件从原路径拷贝到其他路径修改，文件的用户和用户组会自动修改，覆盖原路径的文件后需要执行sudo chown -R root:wheel com.oracle.oss.mysql.mysqld.plist sudo plutil -lint com.oracle.oss.mysql.mysqld.plist 检查语法 sudo launchctl load -w com.oracle.oss.mysql.mysqld.plist 加载（必须） 到此修改完成，通过sqlshow variables like 'log_bin'查看是否开启 p.s. 在成功开启binlog功能后，每次启动mysql就会生成一个binlog文件。若log-bin=/usr/local/mysql/binlog，则会生成/usr/local/mysql/binlog.000001文件（后缀数字会递增）。当修改log-bin路径时，需要考虑到binlog文件的迁移，不然启动mysql会报错 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【MySQL】开启mysql的binlog功能","feature":"","link":"https://xuyj1111.github.io/kI8Q0fvfJ/","stats":{"text":"3 min read","time":176000,"words":695,"minutes":3},"date":"2022-08-16 09:29:40","dateFormat":"2022-08-16"},{"content":" https://leetcode.cn/problems/zigzag-conversion/ 题目描述 将一个给定字符串 s 根据给定的行数 numRows ，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 &quot;PAYPALISHIRING&quot; 行数为 3 时，排列如下： P A H N A P L S I I G Y I R 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：&quot;PAHNAPLSIIGYIR&quot;。 请你实现这个将字符串进行指定行数变换的函数： string convert(string s, int numRows); 思路 一开始使用二维数组，但是发现提前开辟数组空间比较麻烦，很容易NullPointerException或者IndexOutOfBoundsException，所以决定用集合 根据题目中的 Z 字形，则需要变量自增或自减来定位行数，定义变量flag决定自增或自减。开始想到用布尔型 true | false，后根据他人解题思路，使用整型 1 | -1 更为合适 定义变量yy定位行数 public String convert(String s, int numRows) { if (numRows &lt; 2) return s; List&lt;List&lt;String&gt;&gt; lists = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; numRows; i++) { lists.add(new ArrayList&lt;&gt;()); } int flag = -1; int yy = 0; for (char c : s.toCharArray()) { lists.get(yy).add(String.valueOf(c)); if (yy == 0 || yy == numRows - 1) { flag = -flag; } yy += flag; } StringBuilder result = new StringBuilder(); lists.forEach(list -&gt; result.append(String.join(&quot;&quot;, list))); return result.toString(); } ","tags":[{"index":-1,"name":"算法","slug":"t4VskHTZo","used":true,"link":"https://xuyj1111.github.io/t4VskHTZo/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"Z 字形变换","feature":"","link":"https://xuyj1111.github.io/LObGAhooa/","stats":{"text":"2 min read","time":89000,"words":334,"minutes":2},"date":"2022-08-14 16:19:52","dateFormat":"2022-08-14"},{"content":" log4j.properties 是 log4j 的配置文件 在 SpringBoot 架构下，该配置文件路径默认在resources文件夹下 示例 #将等级为DEBUG的日志信息输出到console和file这两个目的地，console和file的定义在下面的代码 log4j.rootLogger=DEBUG,console,file #控制台输出的相关设置 log4j.appender.console = org.apache.log4j.ConsoleAppender log4j.appender.console.Target = System.out log4j.appender.console.Threshold=DEBUG log4j.appender.console.layout = org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern=[%c]-%m%n #文件输出的相关设置 log4j.appender.file = org.apache.log4j.RollingFileAppender log4j.appender.file.File=/Users/edy/logs/all.log log4j.appender.file.MaxFileSize=10mb log4j.appender.file.Threshold=DEBUG log4j.appender.file.layout=org.apache.log4j.PatternLayout log4j.appender.file.layout.ConversionPattern=[%p][%d{yy-MM-dd}][%c]%m%n #日志输出级别 log4j.logger.org.mybatis=DEBUG log4j.logger.java.sql=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG 详情 log4j.rootLogger：把指定级别以上的日志信息输出到指定的一个或者多个位置 语法：log4j.rootLogger = [ level ] , appenderName, appenderName, … level：是日志优先级，为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别【Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG】 appenderName：自定义位置别名 log4j.appender.appenderName：设置输出位置，appenderName为上方自定义的位置别名 org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 其他配置对应不同“输出位置”，各自的配置 占位符 %m 输出代码中指定的日志信息 %p 输出优先级，及 DEBUG、INFO 等 %n 换行符（Windows平台的换行符为 &quot;\\n&quot;，Unix 平台为 &quot;\\n&quot;） %r 输出自应用启动到输出该 log 信息耗费的毫秒数 %c 输出打印语句所属的类的全名 %t 输出产生该日志的线程全名 %d 输出服务器当前时间，默认格式为 ISO8601，也可以在后面指定格式。如：%d{yyyy年MM月dd日 HH:mm:ss} %l 输出日志时间发生的位置，包括类名、发生的线程，以及在代码中的行数，如：Test.main(Test.java:10) %F 输出日志消息产生时所在的文件名称 %L 输出代码中的行号 %x 输出和当前线程相关的 NDC（嵌套诊断环境） %% 输出一个 &quot;%&quot; 字符 可以在 % 与字符之间加上修饰符来控制最小宽度、最大宽度和文本的对其方式。如： %5c 输出category名称，最小宽度是5，category&lt;5，默认的情况下右对齐 %-5c 输出category名称，最小宽度是5，category&lt;5，&quot;-&quot;号指定左对齐,会有空格 %.5c 输出category名称，最大宽度是5，category&gt;5，就会将左边多出的字符截掉，&lt;5不会有空格 %20.30c category名称&lt;20补空格，并且右对齐，&gt;30字符，就从左边交远销出的字符截掉 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"log4j.properties的配置详情","feature":"","link":"https://xuyj1111.github.io/SuwnAF7n7/","stats":{"text":"4 min read","time":195000,"words":775,"minutes":4},"date":"2022-08-04 15:26:35","dateFormat":"2022-08-04"},{"content":" Shell、Bash、Zsh这都是啥啊，by 小白码上飞 Bash 和 Zsh 都是 shell 命令行窗口 Bash Bash 全称为 Bourne-Again Shell，是对 sh 的重写版，替代了 sh，是 Linux 的默认 Shell 配置文件 /etc/profile：为系统的每个用户设置环境信息，当用户第一次登录时会执行该文件里的命令。默认会直接调用/etc/bashrc。该文件的改动需要重启才能生效 /etc/bashrc：为每一个运行 bash shell 的用户执行此文件。当 bash shell 被打开时，会读取并执行该文件中的命令。所以修改该文件后，重新打开 Shell 即可生效 ~/.bash_profile：和/etc/profile类似，但是只对当前用户生效 ~/.bashrc：和/etc/bashrc类似，但是只对当前用户生效 ~/.bash_logout：当每次退出 bash shell 时，执行该文件 ~/.bash_history：保存了历史命令。在 Shell 为 Bash 时，每次敲击命令时，都会保存在这个文件里 Zsh Zsh 即 Z shell，Zsh 对 sh 做出了大量改进，同时加入了 Bash、ksh 及 tcsh 的某些功能 从 2019 年起，macOS 的默认 Shell 从 Bash 改为 Zsh 配置文件 ~/.zshenv：存放的环境变量配置项在任何场景下都能被读取，这里通常把 $PATH 等变量写在这里，这样无论是在交互 shell，或者运行程序都会读取此文件。个人理解对标 Bash 的 profile ~/.zprofile：和 .zlogin 类似，但是是在 .zshrc 之前加载 ~/.zshrc：在交互式 shell 中会读取并执行该文件，包含设置别名、函数、选项、键绑定等命令。对标 bashrc ~/.zlogin：在 login shell 的时候读取 ~/.zlogout：退出终端的时候读取，用于做一些清理工作。对标 bash_logout ~/.zsh_history：保存了历史命令。在 Shell 为 Zsh 时，每次敲击命令时，都会保存在这个文件里 读取顺序：.zshenv → [.zprofile if login] → [.zshrc if interactive] → [.zlogin if login] → [.zlogout sometimes] .zshrc（.bashrc）的使用 在这个文件中，可自定义一些操作 给已存在的命令起别名，实现新建命令的操作 例：Mac 没有 updatedb命令，则在此文件中写入alias updatedb='echo jayxcyujz | sudo -S /usr/libexec/locate.updatedb' 一些命令 查看当前 Linux 的全部 Shell：cat /etc/shells 查看当前使用的 Shell：echo $SHELL或者echo $0 切换默认的 Shell：chsh -s [shell的二进制文件路径]，之后要重新登陆 Shell 才能生效哈。例如： 切换为 Bash：chsh -s /bin/bash 切换为 Zsh：chsh -s /bin/zsh 一些问题 在修改了配置文件后，需要source fileName加载配置文件 因 2019 年起，macOs 的 shell 改为 Zsh。因此在 Bash 的配置文件无效，使用source命令仅会在当前命令行窗口有效，应该在 Zsh 的配置文件中修改 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"Bash和Zsh Shell命令行窗口","feature":"","link":"https://xuyj1111.github.io/Gw0D8kOGj/","stats":{"text":"3 min read","time":161000,"words":695,"minutes":3},"date":"2022-07-13 09:27:04","dateFormat":"2022-07-13"},{"content":" redis 中运行 lua 脚本是原子性的 redis命令执行 此方式需要将 lua 脚本作为字符串传参使用，适合 lua 脚本较短的情况 从 Redis 2.6.0 版本开始，通过内置的 Lua 解释器，可以使用 EVAL 命令对 Lua 脚本进行求值 EVAL命令 语法：EVAL script numkeys key [key ...] arg [arg ...] EVAL：固定 script：一段 Lua 程序，字符串 numkeys：指定键名参数的个数 key[key ...]：键名参数，在 LUA 中使用全局变量 KEYS 数组访问，以 1 为基址开始 arg[arg...]：附加参数，在 LUA 中使用全局变量 ARGV 数组访问，以 1 为基址开始 SCRIPT LOAD命令 将脚本添加到 redis 服务器的缓存中，并不立即执行，返回 SHA1。通过 EVALSHA命令使用 SHA1执行 SCRIPT FLUSH命令清除缓存 语法：SCRIPT LOAD script SCRIPT LOAD：固定 script：一段 Lua 程序，字符串 EVALSHA命令 执行 redis 服务器中的缓存脚本，使用其 SHA1 作为传参 语法：EVALSHA sha1 numkeys key [key ...] arg [arg ...] EVALSHA：固定 sha1：SCRIPT LOAD命令的执行结果 numkeys：指定键名参数的个数 key[key ...]：键名参数，在 LUA 中使用全局变量 KEYS 数组访问，以 1 为基址开始 arg[arg...]：附加参数，在 LUA 中使用全局变量 ARGV 数组访问，以 1 为基址开始 SCRIPT EXISTS命令 传入一个或多个 SHA1，判断指定脚本是否在缓存中，1表示存在，0表示不存在 语法：SCRIPT EXISTS sha1 [sha1 …] SCRIPT EXISTS：固定 sha1[sha1...]：一个或多个脚本的 SHA1 校验和 SCRIPT FLUSH 命令 清除Redis服务端所有 Lua 脚本缓存 语法：SCRIPT FLUSH SCRIPT KILL命令 杀死正在运行的 lua 脚本，此脚本当前没有执行任何写操作时，才会生效 语法：SCRIPT KILL SHUTDOWN NOSAVE命令 若 lua 脚本正在写操作，SCRIPT KILL命令无法关闭，则使用该命令关闭 redis 服务器，防止写入 语法：SHUTDOWN NOSAVE redis-cli客户端执行 此方式可以选择 lua 文件执行 语法：redis-cli --eval file key [key...] , arg [arg...] file：指定 lua 文件【注意路径】 key[key ...]：键名参数，在 LUA 中使用全局变量 KEYS 数组访问，以 1 为基址开始 arg[arg...]：附加参数，在 LUA 中使用全局变量 ARGV 数组访问，以 1 为基址开始 p.s. 不需要指定 key 的数量，key 和 arg 之间使用逗号分隔，逗号两边都需要空格 lua 中使用 redis 命令 redis.call(method, param [param...]) redis.pcall(method, param [param...]) method：redis 方法名【字符串】 param：对应 redis 方法所需的参数 区别：错误处理不同，call 遇到错误停止并抛出；pcall 遇到错误继续运行，最后返回一个带 err 域的 lua 表（table类型） ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"Redis","slug":"FktD58SLR","used":true,"link":"https://xuyj1111.github.io/FktD58SLR/"}],"title":"【Redis】使用Lua脚本","feature":"","link":"https://xuyj1111.github.io/CgFjDynFC/","stats":{"text":"3 min read","time":166000,"words":698,"minutes":3},"date":"2022-07-12 10:58:42","dateFormat":"2022-07-12"},{"content":"介绍 @Valid 和 @Validated都是用来参数校验的 @Valid：是使用 Hibernate 校验时使用 p.s. java的JSR303声明了@Valid这类接口，而Hibernate-validator对其进行了实现 @Validated：是用 Spring 校验时使用 两者的区别 @Valid：可以用在方法、构造函数、方法参数和成员属性上，支持嵌套校验，不支持分组功能 @Validated：可以用在类型、方法和方法参数上。但是不能用在成员属性上，不支持嵌套校验，支持分组功能 校验注解 嵌套校验 使用 @Valid @PostMapping(&quot;/valid&quot;) public void testValid(@RequestBody @Valid TestDTO dto) { System.out.println(&quot;dto: &quot; + dto); } @Data public class TestDTO { @Min(10) private Integer number; /** * @Description: @Valid 的嵌套校验 */ @Valid private InnerDTO innerDTO; @Data public class InnerDTO { @NotNull private Long id; @NotBlank private String name; } } 分组校验 使用 @Validated，此处的示例在GroupInterface中使用 @GroupSequence 注解，以此达到按照该注解中的组顺序依次校验，对未指定组的属性不校验 若写成@Validated({FirstGroupInterface.class})，则表示只对FirstGroupInterface组的属性校验 若写成@Validated({FirstGroupInterface.class, SecordGroupInterface.class})，则表示对多个组的属性校验，但是无序 @PostMapping(&quot;/validated&quot;) public void testValidated(@RequestBody @Validated({GroupInterface.class}) TestDTO dto) { System.out.println(&quot;dto: &quot; + dto); } @Data public class TestDTO { /** * @Description: @Validated 的分组校验 */ @NotEmpty(groups={FirstGroupInterface.class}) private String id; @NotEmpty(groups={SecordGroupInterface.class}) private String name; } 先校验FirstGroupInterface组，再校验SecordGroupInterface组 @GroupSequence({FirstGroupInterface.class, SecordGroupInterface.class}) public interface GroupInterface { } FirstGroupInterface和SecordGroupInterface都是空接口 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】使用@Valid或@Validated参数校验","feature":"","link":"https://xuyj1111.github.io/FOFqe4ayF/","stats":{"text":"2 min read","time":92000,"words":355,"minutes":2},"date":"2022-05-07 16:57:07","dateFormat":"2022-05-07"},{"content":" 域名背后那些事，by LeanCloud 互联网中的地址是数字的 IP 地址，例如61.135.169.125就是百度的官网地址之一，如果每次访问百度都需要输入 IP 的话，估计到今天互联网都还没有走出鸿蒙阶段。 在网络发展历史上，最开始确实就是直接使用 IP 地址来访问远程主机的。早期联网的每台计算机都是采用主机文件（即我们俗称的 hosts 文件）来进行地址配置和解析的，后来联网机器越来越多，主机文件的更新和同步就成了很大的问题。于是，1983 年保罗 · 莫卡派乔斯发明了域名解析服务和域名系统，在 1985 年 1 月 1 日，世界上第一个域名 nordu.net 才被注册成功。 域名比 IP 地址更容易记忆，本质上只是为数字化的互联网资源提供了易于记忆的别名，就像在北京提起「故宫博物院」就都知道指的是「东城区景山前街 4 号」的那个大院子一样。如果把 IP 地址看成电话号码，那域名系统就是通讯录。我们在通讯录里保存了朋友和家人的信息，每次通过名字找到某人打电话的时候，通讯录就会查出与之关联的电话号码，然后拨号过去。我们可能记不下多少完整的电话号码，但是联系人的名字却是一定记得的。 既然「域名」只是一个别名，单凭这一个名字我们并不能访问到正确的地址，只有能将域名解析成实际的网络地址，网络访问才能成功。这种解析工作由专门的「域名系统」（Domain Name System，简称 DNS）完成，DNS 也是互联网的核心基础服务之一。 域名解析是怎么完成的 DNS 解析的过程是什么样子的呢？在开始这个问题之前，我们先看一看域名的层次结构。 域名的层级结构 在讨论域名的时候，我们经常听到有人说「顶级域名」、「一级域名」、「二级域名」等概念，域名级别究竟是怎么划分的呢？ 根域名。还是以百度为例，通过一些域名解析工具，我们可以看到百度官网域名显示为 www.baidu.com.，细心的人会注意到，这里最后有一个 .，这不是 bug，而是所有域名的尾部都有一个根域名。www.baidu.com 真正的域名是 www.baidu.com.root，简写为www.baidu.com.，又因为根域名.root对于所有域名都是一样的，所以平时是省略的，最终就变成了我们常见的样子。 根域名的下一级叫做顶级域名（top-level domain，缩写为 TLD），也叫做一级域名，常见的如 .com / .net / .org / .cn 等等，他们就是顶级域名。 再下一级叫做二级域名（second-level domain，缩写为 SLD），比如 baidu.com。这是我们能够购买和注册的最高级域名。 次级域名之下，就是主机名（host），也可以称为三级域名，比如 www.baidu.com，由此往下，基本上 N 级域名就是在 N-1 级域名前追加一级。 总结一下，常见的域名层级结构如下： 主机名.次级域名.顶级域名.根域名 www.baidu.com.root 一般来说我们购买一个域名就是购买一个二级域名（SLD）的管理权（如 leancloud.cn），有了这个管理权我们就可以随意设置三级、四级域名了。 域名解析的过程 与域名的分级结构对应，DNS 系统也是一个树状结构，不同级别的域名由不同的域名服务器来解析，整个过程是一个「层级式」的。 层级式域名解析体系的第一层就是根域名服务器，全世界 IPv4 根域名服务器只有 13 台（名字分别为 A 至 M），1 个为主根服务器在美国，其余 12 个均为辅根服务器，它们负责管理世界各国的域名信息。在根服务器下面是顶级域名服务器，即相关国家域名管理机构的数据库，如中国互联网络信息中心（CNNIC）。然后是再下一级的权威域名服务器和 ISP 的缓存服务器。 一个域名必须首先经过根数据库的解析后，才能转到顶级域名服务器进行解析，这一点与生活中问路的情形有几分相似。 假设北京市设立了一个专门的「道路咨询局」，里面设置了局长、部长、处长、科员好几个级别的公务员，不同的部门、科室、人员负责解答不同区域的道路问题。这里的人都有一个共同特点，信奉「好记性不如烂笔头」的哲理，喜欢将自己了解到的信息记录到笔记本上。但是有一点遗憾的是，他们写字用的墨水只有一种，叫「魔术墨水」，初写字迹浓厚，之后会慢慢变淡，1 小时之后则会完全消失。道路咨询局门口还有一个门卫大爷，所有的人要问路都需要通过他来传达和回复，市民并不能进入办公楼。 如果市民 A 先生来找门卫大爷询问「北海公园」的地址，门卫大爷会先看一下自己的笔记本，找找看之前有没有人问过北海公园，如果没有，他就会拨打内线去找局长求助。局长说北海是西城区，你去问负责西城区道路信息的赵部长吧。门卫大爷又去问赵部长，赵部长查了一下，说这个地址你去问负责核心区的钱处长吧。门卫大爷又给钱处长打过去电话，钱处长说这个地址我也不掌握啊，你去问一下负责景山片区的科员小孙吧。门卫大爷从小孙那里终于知道了北海公园地址，他赶紧记到自己的小本本上，然后把结果告诉了市民 A 先生。接下来一小时内，如果还有市民 B 先生再来问北海公园的话，门卫大爷就直接用笔记本上记载的结果回复了。当然，如果市民 C 女士过来问别的地址的话，门卫大爷就要把处理 A 先生问询的流程再走一遍了。 分级查询的实例 现在我们来看一个实际的例子。如果我们在浏览器中输入https://news.qq.com，那浏览器会从接收到的 URL 中抽取出域名字段（news.qq.com），然后将它传给 DNS 客户端（操作系统提供）来解析。 首先我们说明一下本机 DNS 配置（就是 /etc/resolv.conf 文件，里面指定了本地 DNS 服务器的地址，Windows 系统可能会有所不同）： $ cat /etc/resolv.conf nameserver 202.106.0.20 nameserver 202.106.196.115 然后我们用 dig 这个工具查看一下 news.qq.com 的解析结果（其中中文部分是解释说明）： $ dig news.qq.com ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; news.qq.com 这是 dig 程序的版本号与要查询的域名 ;; global options: +cmd ;; Got answer: 以下是要获取的内容。 ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 47559 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0 这个是返回应答的头部信息： 1. opcode：操作码，QUERY 代表查询操作； 2. status: 状态，NOERROR 代表没有错误; 3. id：编号，在 DNS 协议中通过编号匹配返回和查询； 4. flags: 标志，含义如下: - qr：query，查询标志，代表是查询操作 - rd：recursion desired，代表希望进行递归查询操作; - ra：recursive available，代表查询的服务器支持递归查询操作; 5. QUERY 查询数，与下面 QUESTION SECTION 的记录数一一对应； 6. ANSWER 结果数，与下面的 ANSWER SECTION 的记录数一一对应； 7. AUTHORITY 权威回复数，如果查询结果由管理域名的域名服务器而不是缓存服务器提供的，则称为权威回复。 0 表示所有结果都不是权威回复； 8. ADDITIONAL 额外记录数； ;; QUESTION SECTION: ;news.qq.com. IN A 查询部分,从左到右部分意义如下: 1、要查询的域名； 2、要查询信息的类别，IN 代表类别为 IP 协议，即 Internet。 3、查询的记录类型，A 记录(Address)代表要查询 IPv4 地址。 ;; ANSWER SECTION: news.qq.com. 136 IN CNAME https.qq.com. https.qq.com. 476 IN A 125.39.52.26 回应部分，从左到右各部分意义： 1、对应的域名 2、TTL，time to live，缓存时间，单位秒，代表缓存域名服务器可以在缓存中保存的期限。 3、查询信息的类别 4、查询的记录类型，CNAME 表示别名记录，A 记录(Address)代表 IPv4 地址。 5、域名对应的 ip 地址。 ;; Query time: 56 msec ;; SERVER: 202.106.0.20#53(202.106.0.20) 查询使用的服务器地址和端口,其实就是本地 DNS 域名服务器 ;; WHEN: Thu Jul 11 15:59:37 CST 2019 ;; MSG SIZE rcvd: 65 查询的时间与回应的大小，收到 65 字节的应答数据。 从这个应答可以看到，我们得到的结果不是权威回复，只是本地 DNS 服务器从缓存中给了应答。 接下来我们在 dig 命令中增加一个参数 +trace，看看完整的分级查询过程： $ dig +trace news.qq.com ; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; +trace news.qq.com ;; global options: +cmd . 432944 IN NS g.root-servers.net. . 432944 IN NS k.root-servers.net. . 432944 IN NS b.root-servers.net. . 432944 IN NS h.root-servers.net. . 432944 IN NS i.root-servers.net. . 432944 IN NS f.root-servers.net. . 432944 IN NS d.root-servers.net. . 432944 IN NS e.root-servers.net. . 432944 IN NS j.root-servers.net. . 432944 IN NS l.root-servers.net. . 432944 IN NS c.root-servers.net. . 432944 IN NS m.root-servers.net. . 432944 IN NS a.root-servers.net. ;; Received 228 bytes from 202.106.0.20#53(202.106.0.20) in 45 ms 这些就是神秘的根域名服务器，由本地 DNS 服务器返回了所有根域名服务器地址。 com. 172800 IN NS g.gtld-servers.net. com. 172800 IN NS a.gtld-servers.net. com. 172800 IN NS b.gtld-servers.net. com. 172800 IN NS m.gtld-servers.net. com. 172800 IN NS d.gtld-servers.net. com. 172800 IN NS c.gtld-servers.net. com. 172800 IN NS j.gtld-servers.net. com. 172800 IN NS h.gtld-servers.net. com. 172800 IN NS f.gtld-servers.net. com. 172800 IN NS l.gtld-servers.net. com. 172800 IN NS e.gtld-servers.net. com. 172800 IN NS k.gtld-servers.net. com. 172800 IN NS i.gtld-servers.net. ;; Received 1171 bytes from 192.36.148.17#53(i.root-servers.net) in 57 ms 这里显示的是 .com 域名的 13 条 NS 记录，本地 DNS 服务器向这些顶级域名服务器发出查询请求， 询问 qq.com 的 NS 记录。 qq.com. 172800 IN NS ns1.qq.com. qq.com. 172800 IN NS ns2.qq.com. qq.com. 172800 IN NS ns3.qq.com. qq.com. 172800 IN NS ns4.qq.com. ;; Received 805 bytes from 192.48.79.30#53(j.gtld-servers.net) in 331 ms 这里显示的是 qq.com 的 4 条 NS 记录，由 j.gtld-servers.net 这台服务器最先返回。 然后本地 DNS 服务器向这四台服务器查询下一级域名 news.qq.com 的 NS 记录。 news.qq.com. 86400 IN NS ns-cnc1.qq.com. news.qq.com. 86400 IN NS ns-cnc2.qq.com. ;; Received 180 bytes from 58.144.154.100#53(ns4.qq.com) in 37 ms 这里显示的是 news.qq.com 的 NS 记录，它们是由上面的 ns4.qq.com 域名服务器返回的。 然后本地 DNS 服务器向这两台机器查询 news.qq.com 的主机名。 news.qq.com. 600 IN CNAME https.qq.com. https.qq.com. 600 IN A 125.39.52.26 ;; Received 76 bytes from 223.167.83.104#53(ns-cnc2.qq.com) in 29 ms 这是上面的 ns-cnc2.qq.com 返回的最终查询结果： news.qq.com 是 https.qq.com 的别名，而 https.qq.com 的 A 记录地址是 125.39.52.26 实际的流程里面，本地 DNS 服务器相当于门卫大爷，根域名服务器相当于局长同志，其余以此类推。客户端与本地 DNS 服务器之间的查询叫递归查询，本地 DNS 服务器与其他域名服务器之间的查询就叫迭代查询。 域名记录的类型 域名服务器之所以能知道域名与 IP 地址的映射信息，是因为我们在域名服务商那里提交了域名记录。购买了一个域名之后，我们需要在域名服务商那里设置域名解析的记录，域名服务商把这些记录推送到权威域名服务器，这样我们的域名才能正式生效。 在设置域名记录的时候，会遇到「A 记录」、「CNAME」 等不同类型，这正是前面做域名解析的时候我们碰到的结果。这些类型是什么意思，它们之间有什么区别呢？接下来我们看看常见的记录类型。 A 记录。A (Address) 记录用来直接指定主机名（或域名）对应的 IP 地址。主机名就是域名前缀，常见有如下几种： www：解析后的域名为 www.yourdomain.com，一般用于网站地址。 @：直接解析主域名。 *：泛解析，指将 *.yourdomain.com 解析到同一 IP。 CNAME 记录。CNAME 的全称是 Canonical Name，通常称别名记录。如果需要将域名指向另一个域名，再由另一个域名提供 IP 地址，就需要添加 CNAME 记录。 MX 记录。邮件交换记录，用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。 NS 记录。域名服务器记录，如果需要把子域名交给其他 DNS 服务器解析，就需要添加 NS 记录。 AAAA 记录。用来指定主机名（或域名）对应的 IPv6 地址，不常用。 TXT 记录。可以填写任何东西，长度限制 255。绝大多数的 TXT 记录是用来做 SPF 记录（反垃圾邮件），MX 记录的作用是给寄信者指明某个域名的邮件服务器有哪些。SPF 的作用跟 MX 相反，它向收信者表明，哪些邮件服务器是经过某个域名认可会发送邮件的。 显性 URL。从一个地址 301 重定向（也叫「永久性转移」）到另一个地址的时候，就需要添加显性 URL 记录。 隐性 URL。从一个地址 302 跳转（也叫「临时跳转」）到另一个地址，需要添加隐性 URL 记录。它类似于显性 URL，区别在于隐性 URL 不会改变地址栏中的域名。 在填写各种记录的时候，我们还会碰到一个特殊的设置项——TTL，生存时间（Time To Live）。 TTL表示解析记录在 DNS 服务器中的缓存时间，时间长度单位是秒，一般为 3600 秒。比如：在访问news.qq.com时，如果在 DNS 服务器的缓存中没有该记录，就会向某个 NS 服务器发出请求，获得该记录后，该记录会在 DNS 服务器上保存TTL的时间长度，在TTL有效期内访问news.qq.com，DNS 服务器会直接缓存中返回刚才的记录。 DNS 智能解析 DNS 主要的工作就是完成域名到 IP 的映射，但是也不是简单到查查字典就可以搞定的程度。在设置 DNS 解析的时候，我们还有一些额外的需求，例如： 将一个域名解析到多个 IP 例如我们一个网站有多台前端机，希望用户访问的时候，可以随机分散到这些机器上，以增加网站承载能力。有一种解决的办法就是对同一个域名设置多条 A 记录，分别指定到不同的 IP 上。 根据特征差异将不同请求解析到不同 IP（智能解析） 国内互联网的架构其实远比我们想象的复杂，基本上还是根据运营商的不同切割成多个平行网络，只有在固定的几个节点这些平行网络才会有交叉。例如电信和联通之间的互联是通过「国家级互联网骨干直联点」接入的，目前我们一共建设了三批国家级互联网骨干直联点： 第一批 2001 年投入使用：北京，上海，广州 第二批 2014 年投入使用：成都，郑州，武汉，西安，沈阳，南京，重庆 第三批 2017 年投入使用：杭州，贵阳 / 贵安，福州 教育网目前还只能通过北上广三个点进行连接。这样的网络拓扑结构，给 DNS 解析带来了新的挑战。 传统 DNS 解析，不判断访问者来源，会随机选择其中一个 IP 地址返回给访问者。如果让电信用户使用了联通 IP 来访问网站，那结果自然不如使用电信 IP 访问来的快捷。而智能 DNS 解析，会判断访问者的来源特征，为不同的访问者返回不同的 IP 地址，能够减少解析时延，并提升网络访问速度。例如，国内某著名 DNS 服务商不光可以区分网络运营商，还可以根据访问者的地理位置来设置不同的解析线路，而且甚至还可以为搜索引擎设置特定的解析地址。 CNAME 和 A 记录区别 按照前面的解释，A 记录就是把一个域名解析到一个 IP 地址，而 CNAME 记录就是把一个域名解析到另外一个域名，其功能差不多。但是 CNAME 相当于将域名和 IP 地址之间加了一个中间层，可以带来很大的灵活性，特别是当你要使用但是并不拥有那些域名的时候。 例如我们使用 CDN 服务，服务商提供给我们的是一个 CNAME 地址，我们可以把自己的域名绑定到这一个地址上，这样万一以后服务商的 IP 地址更换了，我们自己的域名解析是不需要做任何变更的，只要服务商调整一下 CNAME 地址的解析结果，所有使用者都可以无感知的切换。 从 6 月底开始，LeanCloud 新推出了绑定自定义域名的功能，全面支持开发者设置自己的 API、文件、云引擎域名，也正是依赖于 CNAME 记录的这一特点来实现的。 DNS 污染与安全挑战 DNS 是最早商用的大型分布式系统，虽然现在看起来已经很完备了，但是实际使用的时候，特别是国内复杂的网络环境，我们还是会遇到很多问题。 作为互联网早期产物，DNS 使用无连接的 UDP 协议虽然降低了开销也保证了高效的通信，但是没有太考虑安全问题。由于它使用目的端口为 53 的 UDP 明文进行通信，DNS 解析器识别是自己发出的数据包的唯一标准就是随机的源端口号，如果端口号匹配则认为是正确回复，而不会验证来源。所以也带来了诸如 DNS 欺骗、DNS Cache 污染、DNS 放大攻击等问题，同时给一些区域运营商带来了「商机」。 为此业界提出了 DNSSec（Domain Name System Security Extensions，也叫「DNS 安全扩展」）机制，使用密码学方法，让客户端对域名来源身份进行验证，并且检查来自 DNS 域名服务器应答记录的完整性，以及验证是否在传输过程中被篡改过，等等一系列措施来保证数据通信的安全性。对这方面感兴趣的读者，可以关注我们的后续文章。 ","tags":[{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"【转载】域名背后那些事","feature":"","link":"https://xuyj1111.github.io/a9PYxb2n7/","stats":{"text":"20 min read","time":1160000,"words":5091,"minutes":20},"date":"2022-04-29 11:29:41","dateFormat":"2022-04-29"},{"content":" 原码、反码、补码、左移、右移、&amp;、| 【&lt;&lt;】通过位运算实现取余效果 为变量定一个二进制长度，例如定二进制长度而 4 位，则变量最大值： ~(-1L &lt;&lt; 4) = 15 但是在代码中并没有一个数值类型能指定一个可变位数，仅有 int(32位)、long(64位)等，如果想要指定位数（及指定最大值），则需要实现超过最大值后自动从 0 开始，例如： long number = 15; number = (number + 1) &amp; getMaxNum(); //number = 0 getMaxNum() = ~(-1L &lt;&lt; 4) p.s. 相对于取余(%)，位运算速度更快 【&lt;&lt;】拼接成一个Long 符号位 空白位 appId deltaSeconds workId sequence 1bit 11bits 5bits 30bits 4bits 13bits appId &lt;&lt; (13 + 4 + 30) | deltaSeconds &lt;&lt; (13 + 4) | workerId &lt;&lt; 13 | sequence; 持续更新。。。 ","tags":[{"index":-1,"name":"持续更新","slug":"tMXGs2hmt","used":true,"link":"https://xuyj1111.github.io/tMXGs2hmt/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"使用二进制编程心得","feature":"","link":"https://xuyj1111.github.io/dFvS6kPBm/","stats":{"text":"1 min read","time":49000,"words":196,"minutes":1},"date":"2022-04-28 16:35:23","dateFormat":"2022-04-28"},{"content":" 原文地址 www.modb.pro，by 茶叶蛋日常 标记一个调用，一笔日志，一笔交易，经常会需要生成一个唯一 ID，而生成唯一 ID 的形式有很多，常常使用的，便是 UUID (Universally Unique Identifier)。UUID 十分方便，无需网络，效率也高，Java 等语言都提供了相关接口，很容易就能得到一个全球唯一的 ID。 2a7b067b-ea89-4bb5-9aa6-51596d4d53c0 UUID 的生成规则里包含了硬件标识、时间戳、计数器等信息。但却有个比较不爽的点，就是 UUID 的长度，即使用 16 进制表示，依然有 32 位之长，这增加了传输以及存储的成本。 自增序列或许是最直接的一种形式，设计一个计数器，每次获取便自增，这样可以保证序号唯一，且逻辑简单，效率高。这在单机器下十分方便，但考虑到分布式场景，自增序列计数器的位置便不那么简单。倘若各个机器各放置一个，则可能产生相同的 ID，而倘若将自增值存储在数据库，Zookeeper 或者 Redis 上，则增加了网络开销。若是出现不合理的锁争用等情况，那获取一个序号花上十几毫秒，便不那么好接受。 考虑将时间戳作为唯一 ID。比如 Java 中，可以取 System.currentTimeMillis()，即 1970-1-1 日 0 点到现在的毫秒值，以当前的时间来计算，大概得到一个递增的 13 位的十进制数字。但这是一个不怎么明智的选择。假若 CPU 效率高，在同一毫秒内序号生成被调用了多次，则会获得相同的 ID。那么考虑在时间戳的基础上，增加一个 N 位的自增序列，记录每一毫秒生成的 ID 数呢，那又回到了自增序列存放位置的问题。 而即使自增序列的问题解决了，又怎么保证时间戳是一往无前的呢？如果保证选择是 0 时 0 分 0 秒，下一瞬间不会变成 23 时 59 分 59 秒呢？ 事实上时间回拨是可能发生的。除却一些异常场景，一天的时间并不是那么准确的 24X60x60=86400 秒，地球有时候转得快，有时候转得慢。而电脑的时钟（也许是晶振吧）却是相对比较稳定的。这就导致了每隔一段时间就会出现闰秒。这对日常生活可能没什么影响，但表现在计算机上，那就是时间回溯了。那这种情况下，按我们的算法，ID 不就重复生成了么？ 那么，倘若是分布式场景下，我们要生成一个唯一 ID，首先我们不希望生成一个 ID 耗费的资源太多，至少不要有什么网络开销。那必然我们需要在 ID 的生成规则里，加入机器的硬件标识。 在这个基础上，使用时间戳加自增序号是一个比较容易想到的形式。但时间回拨的问题，对一些业务系统不是那么容易接受。 考虑解决时间回拨的问题，为了知道当前时间被回拨了。我们需要一个标志位，记录上一次生成 ID 的时间，每次生成 ID 的时候，都跟这个时间戳进行比较，如果当前时间戳在这之前，则表示发生了时间回拨。当得知发现时间回拨的时候，如何处理呢？ 直接抛出异常，等待程序员处理？虽然是小概率事件，但不应该是序号生成器编码人员应该忽略的问题。 线程进入等待，直到当前时间戳大于上一时间戳？也许是个方式，但加入回拨了一秒，那就需要程序等待一秒，这对于实时性及可用性要求比较高的流程，可能不是很能接受。 比较常用的方式是在出现时间回拨时，使用上一时间戳的序号来继续累加。比如上一秒时 0 时 0 分 0 秒，自增序号到达了 x。因为时间回拨，下一秒时间是 23 时 59 分 59 秒，那么下一次生成序号，发现当前时间戳小于上一时间戳时，则使用 0 时 0 分 0 秒的，自增序号使用 x+1。但，虽然概率不高，自增序号用完后，是不是又得重新等待呢？ 或者，我们也可以使用一个虚拟分配的硬件标志，或者一个不可能发生的时间位置，在发生时间回拨的时间区间内，用来生成唯一 ID。 硬件标志、时间戳、序号，这种序号生成方式，当前最流行的莫过于雪花算法了。经典的雪花算法，使用 0+41 位毫秒级时间戳 + 10 位硬件标志 + 12 位序号 总共 64 位的二进制生成。 雪花算法相对于 UUID 而言，存储的长度仅为一半，更方便的是，通过生成的 ID 可以倒推出一些信息，则 ID 呈自增实行，不会像 UUID 一样摸不着头脑。 而上面的方式，也就是多种处理了时间回拨的雪花方法。网上改进雪花算法的方式很多，但实际如何改进雪花算法来生成 ID 最佳，这可能更多的取决于使用场景。 ","tags":[{"index":-1,"name":"转载","slug":"JDrWa3FBq","used":true,"link":"https://xuyj1111.github.io/JDrWa3FBq/"},{"index":-1,"name":"杂记","slug":"CseDYEWrD","used":true,"link":"https://xuyj1111.github.io/CseDYEWrD/"}],"title":"【转载】雪花算法与时间回拨","feature":"","link":"https://xuyj1111.github.io/812AbNpSc/","stats":{"text":"5 min read","time":293000,"words":1404,"minutes":5},"date":"2022-04-28 16:16:02","dateFormat":"2022-04-28"},{"content":" TimeUnit 表示给定单元粒度的时间段 常用的颗粒度： TimeUnit.DAYS天 TimeUnit.HOURS小时 TimeUnit.MINUTES分钟 TimeUnit.SECONDS秒 TimeUnit.MILLISECONDS毫秒 颗粒度转换 1 天转换为 24 小时 TimeUnit.DAYS.toHours(1) 1 小时转换为 60*60 秒 TimeUnit.HOURS.toSeconds(1) 3 天转换为 72 小时 TimeUnit.HOURS.convert(3, TimeUnit.DAYS) 线程等待 可替代Thread.sleep() 线程等待 1 秒 TimeUnit.SECONDS.sleep(1); ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】TimeUnit的使用","feature":"","link":"https://xuyj1111.github.io/wmN375vyy/","stats":{"text":"1 min read","time":26000,"words":100,"minutes":1},"date":"2022-04-28 15:27:09","dateFormat":"2022-04-28"},{"content":" 可以用来修饰：类 、变量、方法，不能用来修饰抽象类和接口 final变量 final变量只能被赋值一次，赋值后值不再改变 final修饰成员变量 非 static 的初始化方式： 在变量声明的时候赋值 在变量所在的类的构造函数中赋值 在非静态的代码块中赋值 static 的初始化方式： 在变量声明的时候赋值 在静态的代码块中赋值 p.s. 不能在构造方法中赋值 final修饰局部变量 需要在定义时赋值，或者在后续代码中赋值，仅一次有效 final方法 final方法不能被重写 p.s. 不能修饰构造方法 final类 final修饰的类不能被继承 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"}],"title":"【Java】final关键字","feature":"","link":"https://xuyj1111.github.io/zriZx5dsI/","stats":{"text":"1 min read","time":41000,"words":197,"minutes":1},"date":"2022-04-28 14:33:32","dateFormat":"2022-04-28"},{"content":" 在 IT 中使用，简单讲就是模拟对象使用 引入依赖： implementation 'org.mockito:mockito-core:2.23.4' mock对象 mock 对象不执行真实方法，返回值默认 null mock对象的创建 使用 Mockito 类的静态方法创建 ex. List mockObj = Mockito.mock(List.class); 使用@Mock注解 使用@MockBean注解 mock对象的配置 使用when(​...).thenReturn(​...)方法链定义一个行为 List mockObj = Mockito.mock(List.class); Mockito.when(mockObj.get(0)).thenReturn(&quot;hello world&quot;); System.out.println(mockObj.get(0)); //输出：hello world 可以指定多个返回值，多次调用后会依次返回这些值 Mockito.when(mockObj.get(0)).thenReturn(&quot;1&quot;).thenReturn(&quot;2&quot;).thenReturn(&quot;3&quot;); System.out.println(mockObj.get(0)); //输出：1 System.out.println(mockObj.get(0)); //输出：2 System.out.println(mockObj.get(0)); //输出：3 使用when(​...).thenThrow(​...)方法链定义抛出异常 Mockito.when(mockObj.get(1)).thenThrow(new Exception()); System.out.println(mockObj.get(1)); //抛出异常 p.s. mock 对象也可使用doReturn(...).when(...).methodCall和doThrow(...).when(...).methodCall的写法，和上面没差 mock对象的校验 校验行为，使用verify方法 mockObj.add(&quot;one&quot;); //是否调用方法 Mockito.verify(mockObj).add(&quot;one&quot;); //方法调用的次数 Mockito.verify(mockObj, Mockito.times(1)).add(&quot;one&quot;); //是否从未调用方法 Mockito.verify(mockObj, Mockito.never()).add(&quot;two&quot;); //最少调用 1 次 Mockito.verify(mockObj, Mockito.atLeast(1)).add(&quot;one&quot;); //最少调用 1 次 Mockito.verify(mockObj, Mockito.atLeastOnce()).add(&quot;one&quot;); //最多调用 5 次 Mockito.verify(mockObj, Mockito.atMost(5)).add(&quot;one&quot;); 校验方法的执行顺序，使用inOrder方法创建 InOrder 对象 mockObj.add(&quot;two&quot;); InOrder inOrder = Mockito.inOrder(mockObj); //单个 mock 对象的执行顺序校验 inOrder.verify(mockObj).add(&quot;one&quot;); inOrder.verify(mockObj).add(&quot;two&quot;); List mockObj2 = Mockito.mock(List.class); mockObj2.add(111); InOrder inOrder2 = Mockito.inOrder(mockObj, mockObj2); //多个 mock 对象的执行顺序校验 inOrder2.verify(mockObj).add(&quot;two&quot;); inOrder2.verify(mockObj2).add(111); 验证单个或多个 mock 对象没有调用过方法，使用verifyZeroInteractions方法 List mockObj3 = Mockito.mock(List.class); List mockObj4 = Mockito.mock(List.class); Mockito.verifyZeroInteractions(mockObj3, mockObj4); 参数匹配器，使用ArgumentMatchers的静态方法 any() anyXxx() eq(...) endsWith(String) startsWith(String) ...... spy对象 spy 对象会执行真实方法，返回值为真实返回值 p.s. 前提是没有用 Mockito 类的方法代理 spy对象的创建 使用 Mockito 类的静态方法创建 ex. List spyObj = Mockito.spy(List.class); 使用@Spy注解 使用@SpyBean注解 spy对象的配置 doReturn(...).when(...).methodCall不会执行真实方法，同 mock 对象一致 when(​...).thenReturn(​...)会执行真实方法 @Spy、@SpyBean、@Mock、@MockBean区别 spy 和 mock 生成的对象不受 spring 管理 SpyBean 和 MockBean 生成的对象受 spring 管理，相当于自动替换对应类型 bean 的注入 参数捕获 Mockito 允准我们捕获一个 Mock 对象的方法调用所传递的参数 通过argument.capture()获取传参，然后使用argument.getValue()取出参数 List mock = mock(ArrayList.class); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(111); list.add(222); mock.addAll(list); ArgumentCaptor&lt;ArrayList&gt; argument = ArgumentCaptor.forClass(ArrayList.class); verify(mock).addAll(argument.capture()); Assert.assertEquals(2, argument.getValue().size()); Assert.assertEquals(list, argument.getValue()); 延伸 可搭配使用Awaitility——异步操作校验工具，适用于异步请求的IT。即等待异步请求中的某一条件达成，校验后续的代码 ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"}],"title":"【Java】Mockito的使用","feature":"","link":"https://xuyj1111.github.io/iPGLGnAWB/","stats":{"text":"4 min read","time":221000,"words":801,"minutes":4},"date":"2022-04-27 14:44:51","dateFormat":"2022-04-27"},{"content":" 本文选取了参考链接中的部分内容，并且融合了自己的习惯 个人习惯 二级标题之间使用分割线 字符、符号、英文缩写使用单行代码块包住 常用的缩写及符号 Q. question A. answer e.g.例如、举例来说（用于句子中） ex.范例或练习 p.s.备注 标题 文章标题为一级标题，文章内容从二级标题开始，最小三级标题，不可越级 # 一级标题 ## 二级标题 ## 三级标题 若仅有 1 个下级标题，可省略下级标题 ## 二级标题 A ### 三级标题 A （省略） ## 二级标题 B 上一级标题不可与下级标题重名 ## 概述 ### 概述 文本 中文与英文（或半角符号）之间，中文与数字之间，应有半角空格 错误：本文介绍如何快速启动1个Windows系统。 正确：本文介绍如何快速启动 1 个 Windows 系统。 使用简单句或并列句，避免使用复合句 并列句：他昨天生病了，没有参加会议。 复合句：那个昨天生病的人没有参加会议。 使用肯定句表达，避免使用否定句表达 错误：请确认没有接通装置的电源。 正确：请确认装置的电源已关闭。 避免使用双重否定句 错误：没有删除权限的用户，不能删除此文件。 正确：用户必须拥有删除权限，才能删除此文件。 尽量不使用被动语态，改为主动语态 错误：假如此软件尚未被安装， 正确：假如尚未安装这个软件， 不使用冷僻、生造或文言文的词语，而要使用现代汉语的常用表达方式 错误：这是唯二的快速启动的方法。 正确：这是仅有的两种快速启动的方法。 参考链接 中文技术文档的写作规范， by 阮一峰 ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"规范","slug":"pL5x1IP1J","used":true,"link":"https://xuyj1111.github.io/pL5x1IP1J/"}],"title":"写作规范","feature":"","link":"https://xuyj1111.github.io/ueAZWvrkp/","stats":{"text":"2 min read","time":103000,"words":501,"minutes":2},"date":"2022-04-27 09:49:32","dateFormat":"2022-04-27"},{"content":"引入 spring-data-redis 依赖 implementation &quot;org.springframework.data:spring-data-redis&quot; 官网说明文档 与 Redis 连接，有多种连接器。根据官网文档介绍，有以下几种： Jedis connector JRedis connector SRP connector Lettuce connector 以下只介绍 Jedis，但推荐使用 Lettuce，因为 Jedis 线程不安全，Lettuce 线程安全. Jedis 和 Jedis Pool 的具体介绍请参考Jedis和Jedis连接池的基本使用和配置 SpringBoot 自动配置连接 Jedis 在 SpringBoot2.× 使用 jedis，之后被替换为 lettuce 配置信息 在 application.yml 中写配置信息 spring: redis: host: 127.0.0.1 port: 6379 database: 0 password: jedis: pool: max-active: 32 max-wait: -1 max-idle: 8 min-idle: 0 p.s. 新版本的 jedis 中将 maxActive 改成了 maxTotal，MaxWait 改成了 MaxWaitMillis 自动装配 SpringBoot 会自动配置 Redis，所以只需要的地方使用 RedisTemplate @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; 自定义配置连接 Jedis 若需要将 redis 某功能封装成 framework，并可作为第三方包引入使用，则需要自行配置 排除自动装配 @SpringBootApplication(exclude = {RedisAutoConfiguration.class}) 创建配置类 配置 JedisConnectionFactory 和 RedisTemplate Bean，注入 IOC 容器 @Configuration public class RedisConfiguration { @Value(&quot;${spring.redis.host}&quot;) private String host; @Value(&quot;${spring.redis.port}&quot;) private int port; @Value(&quot;${spring.redis.database}&quot;) private int database; @Value(&quot;${spring.redis.password}&quot;) private String password; @Value(&quot;${spring.redis.jedis.pool.max-active}&quot;) private int maxActive; @Value(&quot;${spring.redis.jedis.pool.max-wait}&quot;) private int maxWait; @Value(&quot;${spring.redis.jedis.pool.max-idle}&quot;) private int maxIdle; @Value(&quot;${spring.redis.jedis.pool.min-idle}&quot;) private int minIdle; @Bean public JedisConnectionFactory redisConnectionFactory() { RedisStandaloneConfiguration serverConfig = new RedisStandaloneConfiguration(host, port); serverConfig.setDatabase(database); if (Strings.isNotBlank(password)) { serverConfig.setPassword(password); } JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(maxActive); poolConfig.setMaxWaitMillis(maxWait); poolConfig.setMaxIdle(maxIdle); poolConfig.setMinIdle(minIdle); JedisClientConfiguration.JedisPoolingClientConfigurationBuilder jpcb = (JedisClientConfiguration.JedisPoolingClientConfigurationBuilder) JedisClientConfiguration.builder(); jpcb.poolConfig(poolConfig); JedisClientConfiguration jedisClientConfiguration = jpcb.build(); return new JedisConnectionFactory(serverConfig, jedisClientConfiguration); } @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(JedisConnectionFactory redisConnectionFactory) { RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); //设置序列化，防止乱码 RedisSerializer stringSerializer = new StringRedisSerializer(); redisTemplate.setKeySerializer(stringSerializer); redisTemplate.setValueSerializer(stringSerializer); redisTemplate.setHashKeySerializer(stringSerializer); redisTemplate.setHashValueSerializer(stringSerializer); //刷新配置 redisTemplate.afterPropertiesSet(); return redisTemplate; } } 自动装配 在需要的地方使用 RedisTemplate @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; ","tags":[{"index":-1,"name":"Java","slug":"SOje8Joqr","used":true,"link":"https://xuyj1111.github.io/SOje8Joqr/"},{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"使用手册","slug":"0shj16Tx0","used":true,"link":"https://xuyj1111.github.io/0shj16Tx0/"},{"index":-1,"name":"Redis","slug":"FktD58SLR","used":true,"link":"https://xuyj1111.github.io/FktD58SLR/"}],"title":"【Java】Redis的配置和使用","feature":"","link":"https://xuyj1111.github.io/O9XdzloyU/","stats":{"text":"3 min read","time":149000,"words":496,"minutes":3},"date":"2022-04-06 17:34:12","dateFormat":"2022-04-06"},{"content":"使用命令show plugins;查看所有插件，确定开启表分区功能 创建表分区 ex. CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NULL DEFAULT NULL, PRIMARY KEY (`id`) ) PARTITION BY RANGE(id) ( PARTITION p0 VALUES LESS THAN(10), PARTITION p1 VALUES LESS THAN(20), PARTITION p2 VALUES LESS THAN maxvalue ); 数据表的数据被拆分成几个 ibd 文件，frm 文件是表格式文件 导入数据INSERT INTO test_partition SELECT id,no FROM test WHERE id &lt;= 100; 检索数据SELECT * FROM test_partition partition(p0); RANGE表分区 范围表分区，按一定的范围划分 分区字段必须是整数类型（bit, int ,tinyint,bigint等） 分区的定义范围必须是连续的，且不能重叠 给分区字段赋值时，分区字段的值大小不能超过分区的取值范围 非整数类型字段，可在RANGE()中使用函数进行转换 CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NULL DEFAULT NULL, PRIMARY KEY (`id`) ) PARTITION BY RANGE(id) ( PARTITION p0 VALUES LESS THAN(10), PARTITION p1 VALUES LESS THAN(20), PARTITION p2 VALUES LESS THAN maxvalue ); 语法： PARTITION BY RANGE(xxx) VALUES LESS THAN(...) VALUES LESS THAN maxvalue LIST表分区 列表表分区，指定一个个确定的值 分区字段必须整数类型，或者函数返回的整数 insert插入数据时，数据的分组字段在分区范围内，否则报错：Table has no partition for XXX CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NULL DEFAULT NULL, PRIMARY KEY (`id`) ) PARTITION BY LIST(id) ( PARTITION p0 VALUES IN(1,2,3,4,5), PARTITION p1 VALUES IN(6,7,8,9,10) ); 语法： PARTITION BY LIST(xxx) VALUES IN(...,...,...,) HASH表分区 哈希表分区，根据自定义的数据取余计算，放入对应分区 CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NULL DEFAULT NULL, PRIMARY KEY (`id`) ) PARTITION BY HASH(id) PARTITIONS 4; 语法： PARTITION BY HASH(xxx) PARTITIONS num KEY表分区 KEY表分区，与哈希表分区类似，但是用MySQL自己的HASH函数计算 不写分组字段，默认主键；没有主键则唯一键，唯一键必须not null 分组字段不必是整数类型 分组字段遵循约束条件 CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NOT NULL, PRIMARY KEY (`id`, `no`) ) PARTITION BY KEY(`id`, `no`) PARTITIONS 4; 语法： PRIMARY KEY () PARTITIONS num PRIMARY KEY (xxx) PARTITIONS num PRIMARY KEY (xxx, xxx, ...) PARTITIONS num 多字段分区（range，list） 可以指定多个字段作为分区字段 多分组字段可以使用非整数类型，因此可以创建非整数类型的单分组字段； 对比方向从左往右 CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NOT NULL, PRIMARY KEY (`id`, `no`) ) PARTITION BY RANGE COLUMNS(`id`, `no`) ( PARTITION P0 VALUES LESS THAN(10, 'd'), PARTITION P1 VALUES LESS THAN(20, 'g') ); ----------------------------------------------------------- CREATE TABLE `test_partition` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `no` varchar(50) NOT NULL, PRIMARY KEY (`id`, `no`) ) PARTITION BY LIST COLUMNS(`id`, `no`) ( PARTITION P0 VALUES IN ((1, 'a'), (1, 'b')), PARTITION P1 VALUES IN ((2, 'c'), (2, 'd')) ); range 语法： PARTITION BY RANGE COLUMNS(xxx) PARTITION BY RANGE COLUMNS(xxx, xxx) list 语法： PARTITION BY LIST COLUMNS(xxx) PARTITION BY LIST COLUMNS(xxx, xxx) VALUES IN (..., ...) VALUES IN ((..., ...), (..., ...)) 创建表分区的约束条件 如果表有主键（primary key）或者唯一键（unique key），分区字段必须被包含在主键和唯一键字段的交集部分 是否有主键（primary key） 是否有唯一键（unique key） 分区字段 √ × 在主键字段内 × √ 没有可分区的字段 √ √ 主键和唯一键的交集字段 表分区的使用 使用分区字段做查询时，只查所在分区，否则查询所有分区 分区字段查询 普通字段查询 表分区的优点 提高表存储的数据量（多个文件） 提高查询或修改语句的执行速度（可定位到一个分区或多个分区） 参考链接 MySql表分区的创建与使用，by Bear Coding ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"MySQL","slug":"eng41sp6q","used":true,"link":"https://xuyj1111.github.io/eng41sp6q/"}],"title":"【MySQL】表分区的使用","feature":"","link":"https://xuyj1111.github.io/iJYYroozC/","stats":{"text":"5 min read","time":254000,"words":935,"minutes":5},"date":"2021-09-10 10:07:45","dateFormat":"2021-09-10"},{"content":"一级标题 二级标题 斜体 加粗 斜体加粗 删除写 百度链接 https://www.bilibili.com 引用内容 引用里面也可以使用Markdown语法 嵌套引用 无需列表 有序列表 列表里也可以使用Markdown语法 以下是表格规范： |符号的两侧都需空格 第二行固定 4 个-代表 1 列 不要求书写时每行对齐 月份 收入 支出 8 1000 500 9 1200 600 10 1400 650 可使用:指定列的对齐方向 :----:居中对齐 ----:右对齐 :----左对齐 月份 收入 支出 8 1000 500 9 1200 600 10 1400 650 Sytem.out.println(&quot;单行代码&quot;) public static void main(){ System.out.println(&quot;多行代码&quot;); } ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"规范","slug":"pL5x1IP1J","used":true,"link":"https://xuyj1111.github.io/pL5x1IP1J/"}],"title":"Markdown示例","feature":"","link":"https://xuyj1111.github.io/5u99Umvhx/","stats":{"text":"1 min read","time":42000,"words":176,"minutes":1},"date":"2021-06-16 20:56:15","dateFormat":"2021-06-16"},{"content":"数据库 MySQL Redis 中间件 ActiveMQ RabbitMQ Kafka 构建 Maven Gradle Git SVN Docker Kubernetes 其他 Linux 数据结构 设计模式 Lua脚本 Nginx 正则表达式 Spring Spring Spring MVC Spring Boot Spring Cloud Spring Batch Spring Security Spring Retry 持久化框架 MyBatis MyBatis-Plus Hibernate JPA 第三方 Lombok slf4j + logback——日志框架 Elastic-Job——作业框架 Zookeeper Quartz——定时任务框架 Activiti——业务流程框架 EasyExcel——阿里excel处理框架 ElasticSearch——搜索引擎框架 Sharding-JDBC——分库分表技术 OkHttp——HTTP客户端 Orika——JavaBean映射 Guava——谷歌工具库 Hutool——Java工具包 Jackson——JSON工具类库 Querydsl——SQL构建工具 Flyway——数据库版本管理工具 Curator——Zookeeper客户端 Zip4j——压缩工具包 OpenCSV——csv处理工具包 Awaitility——异步操作校验工具 jjwt——提供JWT创建和验证的Java库 Minio——分布式对象存储服务 测试 REST Assured——HTTP接口测试 Assert——原生断言 Hamcrest——matcher匹配器断言 Mockito——测试框架 持续更新...... ","tags":[{"index":-1,"name":"原创","slug":"WSbjWpIkN","used":true,"link":"https://xuyj1111.github.io/WSbjWpIkN/"},{"index":-1,"name":"总结","slug":"MIh5ain1j","used":true,"link":"https://xuyj1111.github.io/MIh5ain1j/"}],"title":"【TOP】技术及官网文档","feature":"","link":"https://xuyj1111.github.io/38IQbQ0h-/","stats":{"text":"2 min read","time":60000,"words":237,"minutes":2},"date":"2021-05-31 18:10:10","dateFormat":"2021-05-31"}]}